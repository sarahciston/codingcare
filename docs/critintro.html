<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Introduction</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="assets/css/tufte-tt.css">
  <link rel="stylesheet" href="assets/css/pandoc.css">
  <link rel="stylesheet" href="assets/css/pandoc-solarized.css">
  <link rel="stylesheet" href="assets/css/tufte-extra.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<article>
<header>
<h1 class="title">Introduction</h1>
<p class="subtitle">Coding.Care</p>
<p class="byline">17.03.2024</p>
</header>
<nav id="TOC">
<ul>
<li><a href="#why-coding.care" id="toc-why-coding.care">Why
Coding.Care</a>
<ul>
<li><a href="#ai-needs-criticality-and-intersectionality"
id="toc-ai-needs-criticality-and-intersectionality">AI Needs Criticality
and Intersectionality</a></li>
<li><a
href="#critical-ai-needs-creativecritical-codingcritical-intersectional-ai-means-creative-caring-approaches"
id="toc-critical-ai-needs-creativecritical-codingcritical-intersectional-ai-means-creative-caring-approaches">[Critical
AI Needs Creative–Critical Coding][Critical, Intersectional AI Means
Creative, Caring Approaches]</a></li>
</ul></li>
<li><a href="#whats-in-this-collection"
id="toc-whats-in-this-collection">What’s in This Collection</a>
<ul>
<li><a
href="#trans-crafting-queer-transformative-systems-an-introduction"
id="toc-trans-crafting-queer-transformative-systems-an-introduction">TRANS:
<em>Crafting Queer Trans*formative Systems, an
Introduction</em></a></li>
<li><a
href="#craft-coding.care-field-notes-for-making-friends-with-code"
id="toc-craft-coding.care-field-notes-for-making-friends-with-code">CRAFT:
<em>Coding.Care: Field Notes for Making Friends with Code</em></a></li>
<li><a
href="#formative-a-critical-field-guide-for-working-with-machine-learning-datasets-and-inclusive-datasets-research-guide"
id="toc-formative-a-critical-field-guide-for-working-with-machine-learning-datasets-and-inclusive-datasets-research-guide">FORMATIVE:
<em>A Critical Field Guide for Working with Machine Learning
Datasets</em> and <em>Inclusive Datasets Research Guide</em></a></li>
<li><a href="#systems-the-intersectional-ai-toolkit"
id="toc-systems-the-intersectional-ai-toolkit">SYSTEMS: <em>The
Intersectional AI Toolkit</em></a></li>
<li><a href="#interstitial-portals-tactical-refusals"
id="toc-interstitial-portals-tactical-refusals">*: <em>Interstitial
Portals &amp; Tactical Refusals</em></a></li>
</ul></li>
</ul>
</nav>
<!-- >"While specific methods generate a shared terrain of knowledge – which is consequently pervaded by power structures singular methods follow their own logic. While this may avoid the replication of existing structures of power/knowledge, it also creates the problem of the proliferation of parallel universes, which each speak their own, untranslatable language. Practices of artistic research usually partake in both registers, the singular as well as the specific; they speak several languages at once." [@steyerlMeanImages2023] -->
<!-- >"As categories seem to emerge from the data themselves, they acquire the authority of an immediate manifestation or apparition. Data are no longer presented via the traditional media of graphs, clusters, curves, diagrams or other scientific abstractions. Instead, they are visualized in the shape of the thing from which they are supposed to abstract." [@steyerlMeanImages2023]  -->
<!-- >"the same stone can be described from the point of view of a discipline, which classifies and names. But it can also be read as a trace of a suppressed conflict. [...] where is the conflict, or rather what are the extensive sets of conflicts underlying this new academic discipline? Who is currently building its walls, using which materials, produced by whom? Who are the builders of the discipline and where are their traces?" [@steyerlAestheticsResistanceArtistic] -->
<!-- >"This type of apophenia can cause serendipitous misreadings or end you up in jail, that is, but at least not as a docile subjected subject. It (mis-)reads the letter of the law for a love letter, it insists on not recognizing the other at all but rather knowing them in the biblical sense, not as sea of data but as flow of energy, not as pattern-oflife but as wave of desire." [@apprichPatternDiscrimination2018] -->
<!-- >"[In ancient Greece, t]he distinction between speech and noise served as a kind of political spam filter. Dividing signal and noise means not only to "filter" patterns but also to create them in the first place. What does an "anomaly" exactly mean in pattern "recognition"?" [@apprichPatternDiscrimination2018] -->
<!-- >"In general the women of classical literature arc a species given to disorderly and uncontrolled outflow of sound--to shrieking, wailing, sobbing, shrill lament, loud laughter, screams of pain or of pleasure and eruptions of raw emotion in general. [...] Woman is that creature who puts the inside on the outside. By projections and leakages of all kinds — somatic, vocal, emotional, sexual — females expose or expend what should be kept in. [...] Every sound we make is a bit of autobiography. It has a totally private interior yet its trajectory is public. A piece of inside projected to the outside. The censorship of such projections is a task of patriarchal culture that (as we have seen) divides humanity into two species: those who can censor themselves and those who cannot. [...] I wonder if there might not be another idea of human order than repression, another notion of human virtue than self-control, another kind of human self than one based on dissociation of inside and outside. Or indeed, another human essence than self." [@carsonGlassIronyGod1995] -->
<!-- >"the border listens for people in a way that matches them to categories they “should” belong to (e.g. “German”, “Greek”, “Syrian”). When this listening for fails to produce these categories, the border then listens to their bodies with the purpose of uncovering the “truth”⁵ that these border subjects might be concealing. This is the border, human and technological, listening to measurement, performing auscultation, mathematically assessing extracted sonic features. Its listening is inextricably entangled with the economic arrangements of the border and the technological promise of objective truth." [@oliveiraBecomeUndone] -->
<!-- {{ page.subtitle }}
{:.no_toc}

{{ page.title }}
{:.no_toc} -->
<!-- #### Contents -->
<!-- * TOC
{:toc} -->
<!-- * where am I located? locate the self -->
<!-- * what are my stakes? stakes for self -->
<!-- intro 3800, transformative 5600, technocraft 7400, conclusion 2800, ccc guide 25.000 -->
<blockquote>
“I’m stuck here inputting and outputting the data of a story I can’t
change.”
<footer>
–Italo Calvino “The Burning of the Abominable House” <span
class="citation" data-cites="calvinoNumbersDarkOther1976">(1976)</span>
</footer>
</blockquote>
<!-- # [Crafting Queer Trans\*formative Systems] -->
<section id="why-coding.care" class="level1">
<h1>Why Coding.Care</h1>
<p>No intervention in disproportionately harmful algorithmic systems is
possible without critically aware approaches to technologies from deeply
plural perspectives. Meanwhile, no such proliferation of perspectives is
possible without inviting spaces to understand, interrogate, and
reimagine the infrastructures that support those systems.
<em>Coding.Care: Guidebooks for Intersectional AI</em> argues for the
essential entanglement of critical AI approaches and creative-critical
coding communities, showing how each needs the other. It shows what
intersectional, interdisciplinary, creative–critical approaches to AI
systems and other emergent technologies can look like. Its multimodal
guides apply these approaches as in-practice experiments — in different
contexts, for different audiences, for different aspects of these urgent
issues.</p>
<p>The stakes are high: technologies like machine learning urgently
require transformative interventions that recalibrate these systems’
values and their stakeholders. The communities most impacted by them,
and best poised to intervene, currently go unheard as powerful actors
profit from their data and labor exploitation. Large companies warn of
hyperbolic coming dangers in order to distract from the current dangers
they perpetuate. Already-toothless policy recommendations are watered
down and ignored. Meanwhile more and more data represent less and less
diversity, more and more processing power destroys more and more planet.
Glib fun with AI on one side of the world relies on extractive labor for
pennies a day on the other. But why must it be this way?</p>
<blockquote>
<p>“We must begin with the knowledge that new technologies will not
simply redistribute power equitably within already established
hierarchies of difference. The idea that they will is the stuff of
utopian naivete and technological determinism that got us here to begin
with.” <span class="citation"
data-cites="sharmaManifestoBrokenMachine2020">(Sharma 2020)</span></p>
</blockquote>
<p>We cannot expect technology to solve the problems of technology. But
with critical engagement, we can work to return more access, investment,
and community agency to technology by viewing it through different
lenses. We can transform technologies themselves rather than accepting
their current shapes.</p>
<p>How do we participate on our own terms, in order to change systems to
suit us? Especially when learning programming and engaging with tech is
often so intimidating? How do we keep from further marginalizing those
whose perspectives are most necessary in order to face the challenges of
emerging technologies and to change them? How do we reclaim technology
as a human craft?</p>
<blockquote>
<p>“Anyone who has ever woven or knitted knows that one can change
patterns […] but, more importantly, they know <em>there are other
patterns</em>. The web of technology can indeed be woven differently,
but even to discuss such intentional changes of pattern requires an
examination of the features of the current pattern and an understanding
of the origins and the purpose of the present design.” <span
class="citation" data-cites="franklinRealWorldTechnology2004">(Franklin
2004)</span></p>
</blockquote>
<p>I write from particular perspectives that inform how I understand
these urgent concerns and that shape my stakes in them. My interest in
code and AI systems grew from wanting to understand how I might write
stories in new forms, using digital tools that I wanted to build. I am
white, queer, genderqueer, and grew up in the rural Ozarks in the US,
which is the ancestral home of the Osage and Kickapoo nations. I have
been supported with scholarships that let me go far with my education,
while seeing many others who could not. I came late to both queerness
and coding. I spent a long time struggling to learn in tech communities
where I felt I didn’t belong. Still, I was conscious of the growing
impacts that digital tools were having on my voice and on others who
might also feel left out. Over the last decade, I have begun developing
the approaches shared across the works collected in
<em>Coding.Care</em>, as practices of exploration and investigation,
experimentation and imagination, restoration and resistance toward and
with technologies like machine learning. These are practices that ask
how we can better use technology in service of our relations with each
other and in service of building the systems and worlds we want.</p>
<section id="ai-needs-criticality-and-intersectionality" class="level2">
<h2>AI Needs Criticality and Intersectionality</h2>
<blockquote>
“Questions like ‘is a computer creative’ or ‘is a computer an artist’ or
the like should not be considered serious questions, period. In the
light of the problems we are facing at the end of the 20th century,
those are irrelevant questions. Computers can and should be used in art
in order to draw attention to new circumstances and connections and to
forget ‘art’.”
<footer>
–Frieder Nake, “There Should Be No Computer Art” <span class="citation"
data-cites="nakeThereShouldBe1971">(1971)</span>
</footer>
</blockquote>
<p>Questions about art, creativity, and labor in relation to AI are
fundamentally questions trying to define humanity — <em>What makes us
creative or empathetic? What makes us different from machines? What
makes us human?</em> They are old, old questions. They also emerge from
centuries of colonizer thinking that frames ‘man’ as an idealized,
individualized white subject. Hyped AI discourse explores limited
questions about AI because it continues to draw from limited
perspectives, letting status quo narratives about humans and automated
systems frame the terms of debate. “Machine learning […] is an
expression of that which has already been categorized,” says digital
culture researcher Ramon Amaro <span class="citation"
data-cites="amaroBlackTechnicalObject2022">(2022)</span>. Not to think
to train on a variety of faces, or not to raise concerns about training
on faces at all, happens because there is not a variety of perspectives
in the room when these very human decisions are being made: before,
during, and after the data is being collected; before, during, and after
the code is being written and run.</p>
<p>Automated decision-making systems disproportionately harm the
marginalized majority. We are subject to these systems whenever we lend
our data by clicking terms of service pop-ups to make them go away; and
whenever we must be recognized by borders, banks, and bureaucracies of
any kind. Our varied degrees of vulnerability in these moments are
exploited and profited on — from testing biometric facial technologies
in refugee camps <span class="citation"
data-cites="neddenBiometrieGetestetMillionen2017">(Nedden and Dongus
2017)</span> to reinforcement learning reliant on chatbot user responses
and content moderation. Much amazing research has highlighted the
increasing impacts of AI systems and surveillance capitalism <span
class="citation"
data-cites="benderDangersStochasticParrots2021 benjaminRaceTechnologyAbolitionist2019 buolamwiniGenderShadesIntersectional2018 browneDarkMattersSurveillance2015 gebruDrTimnitGebru2021 nobleAlgorithmsOppressionHow2018">(Bender
et al. 2021; Benjamin 2019; Buolamwini and Gebru 2018; Browne 2015;
Gebru 2021; Noble 2018)</span>.</p>
<p>Yet AI hype describes machine learning systems as impenetrable black
boxes, as if to keep us outside of these issues. Black box thinking
permeates the interfaces with which we engage ML tools; it claims the
proprietary restrictions that hide its data (our data); and it
influences the regulations that keep its power in the hands of a select
few. We only break out of those boxes when we refuse to engage on those
terms. “Artificial intelligence uses classification to encode power,”
says critical AI researcher Kate Crawford. She argues that computational
“ways of seeing depend on the twin moves of abstraction and extraction.
But these logics can be challenged, just as systems that perpetuate
oppression can be rejected” <span class="citation"
data-cites="crawfordAtlasAIPower2021">(2021)</span>. The task of
critical AI researchers and makers is to engage these systems as
sociotechncial objects embedded in their historical, social, context,
argue critical AI researchers and professors Rita Raley and Jennifer
Rhee. We must be “situated in proximity to the thing itself, cultivating
some degree of participatory and embodied expertise, whether archival,
ethnographic, or applied <span class="citation"
data-cites="raleyCriticalAIField2023">(Raley and Rhee 2023)</span>.</p>
<p>This requires interdisciplinary and intersectional perspectives. It
also requires what rhetorician Adam Banks calls “transformative access.”
He argues that access is more than owning or using tools, participating
in processes or even critiquing their failings. Transformative access is
“always an attempt to <em>both</em> change the interfaces [where people
use that system] and fundamentally change the codes that determine how
that system works.” Banks highlights the important role Black people
play in technology’s transformations, saying, “Black people have hacked
or jacked access to <em>and</em> transformed the technologies of
American life to serve the needs of Black people and all of its
citizens” <span class="citation"
data-cites="banksRaceRhetoricTechnology2006">(Banks 2006)</span>. As
many Black feminist and intersectional theories argue, supporting the
needs of multiply marginalized people often leads to more effective
support for many others.</p>
<p>Intersectionality, Kimberlé Crenshaw’s iconic analysis of
institutional power <span class="citation"
data-cites="crenshawDemarginalizingIntersectionRace1989">(Crenshaw
1989)</span>, “critiques systems of power and how those systems
structure themselves to impact groups and individuals unequally” <span
class="citation" data-cites="cooperIntersectionality2016">(Cooper
2016)</span>. Intersectionality can reveal the tangible human and
more-than-human costs entangled in these algorithmic systems – their
proliferating data and its material infrastructures, as well as their
consolidating power and its sociocultural infrastructures. Such power is
differential by design. Conversations about AI fairness, transparency,
explainability, ethics, public good, and the hype cycles of new
technologies are grossly incomplete without intersectional analyses of
power and intersectional tactics of (and beyond) equity and inclusion.
No change <em>about</em> us <em>without</em> us.</p>
<p>Yet industry implementations of so-called ethical tech reduce complex
concepts into flattened ideas of fairness and representation <span
class="citation"
data-cites="ovalleFactoringMatrixDomination2023a">(Ovalle et al.
2023)</span>. Machine learning, as a mass production, produces certainty
from uncertainty. It produces a false sense of certainty from millions
or billions of small uncertainties, argues political geographer Louise
Amoore, through its reductionist logics of probability as prediction
<span class="citation"
data-cites="amooreCloudEthicsAlgorithms2020">(Amoore 2020)</span>. These
uncertainties are also claims about “what we should know, how we should
know what we know, and how that knowledge should be deployed. Each
exposure to a dataset occurs because someone concluded that the
information in that dataset should be used to determine a possible
future” <span class="citation"
data-cites="hakopianInstituteOtherIntelligences2022">(Hakopian
2022)</span>. Since an algorithm is at its most simple a set of
instructions, of course it will contain the assumptions of those who
wrote those instructions. It will follow their beliefs about how to
implement that procedure. There are many ways to do any task, informed
by minute choices at every step. As these choices scale exponentially
with computation, the impact of these choices magnifies exponentially
too. For example, because generative AI models have become so large, and
training processes so expensive, they frequently rely on foundation
models: previous models, often designed for other ‘general’ tasks, used
as the building blocks for new models. Like a sourdough starter,
foundation models carry with them the histories of how their datasets
were designed and for what purpose, whose data was included or excluded,
and the choices their creators made when preprocessing them. These are
often decades-old “benchmarks” leaving debunked or erroneous information
in cutting-edge models’ outputs. They are compounded by the
computational speeds that allow thousands of operations to run per
second. Yet, because they are processed through algorithmic systems (and
a mythology of the black box), these choices get normalized,
naturalized, and neutralized.</p>
<p>Yes, in many cases it would be nice to have more, better data. But
the very valid criticism that algorithmic systems are biased because
their data are biased — often summed up “garbage in, garbage out” — sets
up a quest already doomed to fail. What would be better data? Or an
optimized system? For what goal, and for whom exactly? There is no such
thing as unbiased, there is only the right tool for the particular job,
or a given slice of information from a particular perspective with just
enough context for the purposes of a specific task. There is only “good
enough” data — and only sometimes, for some tasks. When the stakes are
too high, no data could be good enough to make life or death decisions.
We need a different approach. We cannot rely on computational systems
for infallibility and rationality, as we have been, nor can we look to
these technologies uncritically as bandaids for the problems they
exacerbate.</p>
<p>While the need for AI oversight is clear, many have been calling for
total overhaul and for algorithmic justice, like computer scientist Joy
Buolamwini <span class="citation"
data-cites="buolamwiniAJLALGORITHMICJUSTICE">(Buolamwini n.d.)</span>.
Still, practical applications of these valid critiques remain difficult
to implement. How do we get there? As I have previously theorized it,
intersectional AI calls for demystifying normative AI systems and
learning from marginalized ethics and tactics, in order to fundamentally
transform AI. It requires multimodal, polyvocal, experimental approaches
that cut through the technological solutionism <span class="citation"
data-cites="cistonIntersectionalAIEssential2019">(Ciston 2019)</span>.
It requires slow, long-term investments in algorithmic justice, rather
than extractive, performative forms of inclusion that erase friction,
context, and agency as they scale up for machine learning tasks <span
class="citation" data-cites="sloaneParticipationNotDesign2022">(Sloane
et al. 2022)</span>. As a term, ‘Trans*formative’ looks for root causes
and radical alternatives — in this case, alternatives to the
computational logics that perpetuate harmful systemic inequities.</p>
<!-- A large interdisciplinary community is pushing for understanding, critiquing, and rethinking how we define, develop, deploy, regulate, use, and mitigate the effects of machine learning tasks, datasets, models, algorithms, architectures, and agents, which we collectively and nebulously understand as 'AI' systems. Critical AI includes critical analysis of the pitfalls of existing methods. In some formulations it calls for applying alternative indigenous, feminist, queer, crip, neurodivergent, and intersectional approaches; however, critical AI is distinguished from applied approaches like 'AI for Good' or 'AI for Society', which can lack critical perspectives despite their intended altruism. Importantly, Critical AI as a set of mixed methods of analysis and intervention has yet to be adopted into standard machine learning practices, even as the use and awareness of AI escalates and its interventions grow more urgent. -->
</section>
<section
id="critical-ai-needs-creativecritical-codingcritical-intersectional-ai-means-creative-caring-approaches"
class="level2">
<h2>[Critical AI Needs Creative–Critical Coding][Critical,
Intersectional AI Means Creative, Caring Approaches]</h2>
<!-- ## We Need Creative–Critical–Caring Approaches  -->
<p><em>How do we reconnect the communities of practice who are building
technologies and those who are equipped with the knowledge to consider
its most urgent questions?</em></p>
<p>Caring, creative, and critical approaches must be combined in order
to adapt the spaces where technologies are discussed, designed, and
implemented. Those spaces are missing the essential perspective of those
pushed to the margins, who are most capable of addressing the urgent
issues facing technology. These concerns are not new, nor strictly
digital. They have been addressed by a wide range of communities with
different types of knowledge for centuries. Many are calling urgently
for Indigenous <span class="citation"
data-cites="CAREPrinciplesIndigenousa haoNewVisionArtificial2022 INDIGENOUSAI escofferyAncestralIntelligenceAI2023">(<span>“CARE
Principles of Indigenous Data Governance”</span> n.d.; Hao 2022;
<span>“INDIGENOUS AI”</span> n.d.; Escoffery 2023)</span>, antiracist
<span class="citation"
data-cites="AntiRacistHCINotes">(<span>“Anti-Racist HCI: Notes on an
Emerging Critical Technical Practice | Extended Abstracts of the 2022
CHI Conference on Human Factors in Computing Systems”</span>
n.d.)</span>, antiableist <span class="citation"
data-cites="hamraieCripTechnoscienceManifesto2019a">(Hamraie and Fritsch
2019)</span>, anticolonialist <span class="citation"
data-cites="chakravarttyVirtualRoundtableDecolonial2018 ravalAgendaDecolonizingData2019 rightsDecolonisingAITransfeminist2020a">(Chakravartty
and Mills 2018; Raval 2019; Rights 2020)</span>, neurodiverse <span
class="citation" data-cites="goodmanSecretLifeAlgorithms">(Goodman,
n.d.)</span>, queer <span class="citation"
data-cites="keelingQueerOS2014 klipphahn-kargeQueereKIComingout">(Keeling
-01-22 2014; Klipphahn-Karge and Koster, n.d.)</span>, intersectional
<span class="citation"
data-cites="cistonIntersectionalAIEssential2019 klumbyteCriticalToolsMachine2022a">(Ciston
2019; Klumbytė, Draude, and Taylor 2022)</span>, and other knowledge
systems to be applied to AI and emergent technologies. Yet intimidating,
isolating cultures around the specialization of computation and
programming practices have left so many of us out of these
conversations.</p>
<p>As code makes contact with the world with increasing complexity, code
literacy becomes increasingly essential. Yet if we want to imagine
different systems, code literacies should not be defined only on the
narrow terms of those creating existing systems <span class="citation"
data-cites="veeCodingLiteracyHow2017">(Vee 2017)</span>. We know that
bootcamps and hiring initiatives, though useful, do not support the goal
of shifting a variety of voices into positions where can effectively
make change <span class="citation"
data-cites="abbateCodingNotEmpowerment2021 hicksSexismFeatureNot2021 dunbar-hesterHackingDiversityPolitics2019 veeCodingLiteracyHow2017">(Abbate
2021; Hicks 2021; Dunbar-Hester 2019; Vee 2017)</span>. They do not
acknowledge the many people already participating in the production of
technologies in the global majority, from those harvesting of rare earth
minerals and circuit board manufacturers <span class="citation"
data-cites="ainowinstituteLaborThatMakes nakamuraIndigenousCircuitsNavajo2014">(AI
Now Institute n.d.; Nakamura 2014)</span> to the content moderators
<span class="citation"
data-cites="robertsCommercialContentModeration2016">(Roberts
2016)</span> to the crowd workers (Sunder 2022). [Joining an ‘elite’
tech field is a moving target, entangled with race, gender, and
globalization politics.] Communications scholar Christina Dunbar-Hester
and others call for interventions that go deeper than training more
people in tech jobs, pointing out that this does little to examine the
structures that organize and value work sectors. She argues this calls
for “a larger reevaluation and appropriation of categories
themselves—the boundaries of what is ‘social’ and what is ‘technical’
are flexible categories” <span class="citation"
data-cites="dunbar-hesterHackingDiversityPolitics2019">(Dunbar-Hester
2019)</span>. [XXX] Part of our work involves noticing how many more
people are potentially already engaged with sociotechnical practices and
implicated by them, as user-practitioners, data subjects and subjectees,
skilled crafters and critics.</p>
<p>We know code means more, if we let it. Code is collaborative, says
Mark C. Marino, who helped develop the practice of Critical Code
Studies. Code can be an inviting, interpretive practice: “Code’s meaning
is communal, subjective, opened through discussion and mutual inquiry,
to be contested and questioned, requiring creativity and
interdisciplinarity, enriched through the variety of its readers and
their backgrounds, intellectually and culturally” <span class="citation"
data-cites="marinoCriticalCodeStudies2020a">(Marino 2020)</span>. Such
approaches invite the creation of hybrid communities that acknowledge
the interdisciplinary capacities of programming, and the diverse
capacities for knowledge.</p>
<p>This requires we reunite the divisions between theory and practice,
between user and programmer, which were artificially split from the
start <span class="citation"
data-cites="AlwaysalreadyprogrammingMda artistBlackGooeyUniverse nardiSmallMatterProgramming1993">(<span>“Always-Already-Programming.md”</span>
n.d.; Artist n.d.; Nardi 1993)</span>. It requires un-siloing domains
and disciplines, the artificial boundaries that divide technologists
from activists and critics from creators. It requires we find common
language and common values that come with working knowledge of the whole
system. The technical how-to means (coding skills) and the
critical/analytical how-to means (analytical, political, aesthetic,
ethical contexts) and the material how-to means (data, energy, hardware)
have to combine and are inseparable.</p>
<blockquote>
<p>“By reinforcing the idea that there is a split between theory and
practice or by creating such a split, both groups [elite academia and
anti-intellectuals] deny the power of liberatory education for critical
consciousness, thereby perpetuating conditions that reinforce our
collective exploitation and repression. –bell hooks <span
class="citation"
data-cites="hooksTeachingTransgressEducation1994">(1994)</span></p>
</blockquote>
<p>All making, all writing, all coding is a hybrid practice of creation
(poetics), critique (politics), and code (platforms and programmatic
systems). <!-- All code is writing and all writing is code.  --></p>
<p>How do we reunite these? We need access. We need everyone’s
contributions to be valued, for the effort toward understanding to be
mutual because all participants know that we each have important
contributions to make. Access includes many aspects. It requires
connecting an individual’s current understanding and circumstances to
the new knowledge step by step. It considers material, financial,
intellectual, social resources that allow for a variety of entry points.
I may be capable of understanding how a machine learning system works,
but not have the prerequisite vocabulary to enter a conversation in
order to learn about it. I may understand how to operate a machine
learning system, but not have the financial resources needed to run a
resource-intensive devices in order to use one. I may have knowledge and
resources to share, but not be able to participate because barrier-free
access, transcription, gender-inclusive language, or other inclusive
aspects were not prioritized by the organizers.</p>
<blockquote>
<p>“any theory that cannot be shared in everyday conversation cannot be
used to educate the public.” <span class="citation"
data-cites="hooksTeachingTransgressEducation1994">(hooks
1994)</span></p>
</blockquote>
<p>Prioritizing access here means prioritizing common language. These
works are written as jargon-free as possible to allow them to travel as
broadly as possible. They also vary in methodology and modality in order
to access different audiences and spaces. They show how different ways
of knowing are necessary to engage the same questions, as well as how
different aspects of the questions must be addressed simultaneously.</p>
<p>This approach makes creativity and care part of its argument. These
are not additions, affectations, or antonyms to critical theory or
technical savvy, but rather they are central fortifications to the work.
Code work is critical work is care work is creative work.</p>
<p>Each of the works in <em>Coding.Care: Guidebooks for Intersectional
AI</em> finds a different balance of these elements but includes all
four. <em>Coding.Care: Field Notes for Making Friends with Code</em>
gives courage to pick up unfamiliar tools, find resources to kick off a
new programming project, pose questions critically, or solve problems
creatively. Its pocket-guide form discusses how to build a cooperative,
interdisciplinary community for co-learning coding like the one I have
facilitated since 2019. The <em>Intersectional AI Toolkit</em>’s
co-authored zines are accessible guides to both AI and
intersectionality, bringing together artists, activists, academics,
makers, technologists, and anyone who wants to understand the automated
systems that impact them. The work argues that established but
marginalized tactics are necessary for reimagining more critical and
ethical machine learning. Together these tools and resources ask:
<em>Whose voices, visions, and stories are captured by automated
systems? Whose are excluded, harmed, or undermined? How can AI systems
be accessible for anyone to engage and intervene in?</em> And <em>A
Critical Field Guide for Working with Machine Learning Datasets</em>
translates critical AI theories and data science concepts into practical
tips for dataset stewardship. Along with the <em>Inclusive Datasets
Research Guide</em>, both guides combine technical skillbuilding and
critical thinking for scholars and practitioners beginning to work with
datasets, because datasets remain the foundation of machine learning as
it grows rapidly in impact. And brief lyric essays offer interludes to
the major works as oblique refractions of their topics.</p>
<p>These works emerge from my artistic research (also called
research-creation or arts-based research in different lineages and
regions). Artistic research is neither research that produces art, nor a
scholarly presentation of art, nor a creative presentation of research,
but instead a hybrid practice of “creation-as-research” and
research-as-creation:</p>
<blockquote>
<p>“By bringing research and creation together in such a way that they
unpredictably contaminate and remake each other, in such a way that they
render each other uncanny, research-creation makes space in the
university for research practices that are grounded in nonhegemonic
literacies […]” “in failing to fully belong, and allowing that
nonbelonging to denaturalize, emergently, its givens, research-creation
tells other stories, uncanny stories, that (have the potential to) carry
within them […] other ethics” <span class="citation"
data-cites="lovelessHowMakeArt2019">(Loveless 2019)</span>.</p>
</blockquote>
<p>Strategies for combining creative and critical practices have been
eloquently described elsewhere <span class="citation"
data-cites="willisFastForwardFuture2016 lovelessHowMakeArt2019 fournierAutotheoryFeministPractice2021">(Willis
2016; Loveless 2019; Fournier 2021)</span>. In my own artistic research,
I am particularly interested in process-oriented experimentation and in
how artistic experiments can challenge paradigms in machine learning,
data science, and technology communities. I have found artistic research
practices can interrogate systems and imagine new ones. For me, artistic
research combines rigorous scholarly investigation, deep community
building and activism, and creative play in ways that facilitate
connections to broader non-academic audiences.</p>
<p>Art has been the space where I am able to unpack complex ideas for
myself, because I can treat them more freely as artistic materials. It
is where I am able to follow instinct and feel into how my tools,
platforms, and forms shape their outputs and outcomes. It is also the
space where I feel able to imagine wildly, creating digital objects that
should exist but don’t, or couldn’t exist but might.</p>
<p>Artistic research opens space beyond research questions, where
research tensions live. In that space, I can sit a bit longer with
questions I know I cannot answer, questions that make me uneasy. I can
hold two contradictory ideas simultaneously and let them push–pull me,
forgiving myself imperatives and outcomes, productivity and proven
hypotheses. I can put myself into the trouble, because I already embody
these questions in my lived experience.</p>
<p>In my experience, this imaginative work is central to supporting very
practical next steps and strategies. It is central to supporting more
open access to communities of practice where others can continue the
kinds of artistic experimentation that challenge paradigms in new forms
I might never imagine. In such contexts, argues [XXX-ID] Holly
Willis:</p>
<blockquote>
<p>“arts-based research is rooted in critical theory, framing the
research process within the context of power, emancipation and a deep
questioning of the ethical and ideological implications of knowledge and
change” <span class="citation"
data-cites="willisFastForwardFuture2016">(Willis 2016)</span>.</p>
</blockquote>
<p>[XXX][ADD] Because of its inquiring forms, such techniques for
reflexive making call for iterative, abductive approaches:</p>
<blockquote>
<p>“In the context of design research, an abductive approach values the
creative, speculative, and even unconscious connections between ideas
and materials that develop when an artist or designer iteratively
produces aesthetic artifacts. There is a value in how new ideas can
quickly emerge through imaginative and experimental transformations,
leaps, and juxtapositions. In terms of the development of new knowledge,
an abductive approach tolerates the role that material craft and
subjectivity play in meaning-making.” (Griffiths 2022)</p>
</blockquote>
<p>[XXX][ADD][connect to this form of transformations, leaps,
iterations, self-reflection, how does this format allow for self
reflection and why self reflection is necessary]</p>
<p>Self-reflection is an essential part of artistic research and related
practices like design research. As an intervention into deep learning
algorithms, [XXX-ID] Catherine Griffiths has argued for
<code>reflexive software development</code> that critically considers
and interactively presents the circumstances of its own production. The
outputs of such research can be tools that continue to probe their
research questions, both through the very processes of their creation
and through their later use by others.</p>
<blockquote>
<p>“Bots can make arguments. […] bots exist to shine a light on how
things already work, but also to test the edge cases, and to propose
alternatives. […] bots are procedures against procedures.” (Allison
Parrish, “Procedure vs Procedure”)</p>
</blockquote>
<blockquote>
<p>“artists, and artist-activists, have introduced new ways of
knowing—ways of apprehending how learning machines learn, and what they
do with what they know. In the process, they’ve also initiated learning
machines into new ways of doing. […] artists have shown how we might
visualize what is not yet here. […] Artistic practice opens up knowledge
systems beyond those canonized in the institutions of the early 21st
century. […] the history of aesthetic practice also contains other
histories, and diagrams of other possible futures.” <span
class="citation"
data-cites="hakopianInstituteOtherIntelligences2022">(Hakopian
2022)</span></p>
</blockquote>
</section>
</section>
<section id="whats-in-this-collection" class="level1">
<h1>What’s in This Collection</h1>
<p>Each section of <em>Coding.Care</em> puts its thinking into action —
tackling related aspects in different forms and for different audiences.
The parts combine to enact the ethics and tactics described in this
introduction. Together these public-facing resources provide plainspoken
translations of technical, critical, aesthetic, and ethical concepts
relevant to technology. They are written in approachable, non-academic
formats like zines, and produced in contexts like workshops, in order to
support discussions across communities of practice — including code
creators, AI researchers, and marginalized outsiders — toward
understanding the urgency of the issues facing automated technologies
and the necessity of each other’s skill sets in facing these issue.</p>
<section
id="trans-crafting-queer-transformative-systems-an-introduction"
class="level3">
<h3>TRANS: <em>Crafting Queer Trans*formative Systems, an
Introduction</em></h3>
<p>As an extended introduction to the theories, metaphors, and tactics
applied throughout this collection, <em>Crafting Queer Trans*formative
Systems</em> looks at [XXX]</p>
</section>
<section id="craft-coding.care-field-notes-for-making-friends-with-code"
class="level3">
<h3>CRAFT: <em>Coding.Care: Field Notes for Making Friends with
Code</em></h3>
<!-- "Coding.Care: Field Notes for Making Friends with Code" describes critical–creative programming approaches founded in the belief that anyone can contribute to the future of digital systems and that we all have skills to teach each other. It gives courage to pick up unfamiliar tools, find resources to kick off a new programming project, pose questions critically, or solve problems creatively. It asks: How do we code with more care? How do we encode more care into our lives? How are these connected? It supports building or joining cooperative, interdisciplinary communities for co-learning coding. "Coding.Care" addresses reluctant or would-be programmers (of any age) and and potential group leaders, with a warm and friendly pocket guide, at the moment where they might intervene with critical or imaginative software creation.  -->
<p><em>Coding.Care</em> is a pocket guide to sustaining friendly coding
communities — why we need them, how to build them, how to let them
thrive. It focuses on lessons I learned from Code Collective, the
diverse hack lab that I started in 2019 when I yearned for the
adaptable, encouraging environment I had needed when I was first
struggling to learn to program. In gratitude to teachers like Brett
Stalbaum, at UC San Diego’s Computing in the Arts program, who had
showed me code could feel creative instead of prescriptive, I wanted to
make a space where I wouldn’t feel like an outsider for ‘not knowing
everything’ about programming, and I suspected others might feel the
same.I wondered how to recreate that experience.</p>
<p>In Code Collective, a mix of media artists, activists, makers,
scientists, scholars, and engineers gather to co-work and co-learn,
thinking critically with code in an inclusive, interdisciplinary space
that supports many kinds of learners. The Collective unites students who
may have zero technical experience with those who may have lots of
technical experience but perhaps lack a critical or creative lens; and
we value their experiences equally, reinforcing the idea: <strong>“We
all have something to teach each other.”</strong></p>
<p>This guide looks at a variety of the strategies and tools we have
explored and developed as we have grown. It discusses how we have
adapted to meet the needs of our community — from hosted workshops to
hybrid-format meetups, from pandemic support to alumni programming. Code
Collective’s approaches draw on many existing methodologies and methods
from intersectional queer, feminist, anti-ableist, and anti-racist
theories. The guide connects these approaches to cooperative
organizations Varia and p5.js, and to Critical Code Studies and to
practices like working iteratively and breaking critically.</p>
<p>As a guide for making friends with code, <em>Coding.Care</em>
discusses how practices such as process-oriented skillbuilding,
co-teaching and co-learning, and snacks (always snacks) embody the
Collective’s guiding values, such as <strong>“scrappy artistic
strategies not perfect code.”</strong> The guide shares projects and
feedback from members of the Collective, who report how these values and
practices have shaped them as emerging makers and thinkers. Personally,
I have found this community to be the strongest influence on my own
research, above and beyond my role as facilitator. Code Collective has
become a joyful space for creative risk-taking that nourishes my
practice. The guide offers practical advice for getting comfortable with
code, while situating these approaches and groups within an
<strong>ethics of coding care</strong> — grounded in shared embodied
knowledge, embedded co-creation, and programming with and for community
— as an antidote to technocratic values and as an enactment of its
ethos.</p>
<p>In her book, <em>Coding Literacy</em>, Annette Vee argues that,
“Changing ‘how the system works’ would move beyond material access to
education and into a critical examination of the values and ideologies
embedded in that education. […] Programming is a literacy practice with
many applications beyond a profession defined by a limited set of
values” <span class="citation"
data-cites="veeCodingLiteracyHow2017">(Vee 2017)</span>. Vee calls this
kind of programming access “transformative.” Through
<em>Coding.Care</em>’s intimidation-free, learner-led, process-oriented
approaches, it both theorizes and models the creation of caring
communities and innovative spaces that can transfer knowledge across
social strata and intellectual disciplines in order to reshape
technological systems.</p>
<p>OBJECTIVES: Through <em>Coding.Care</em>, understand how to approach
programming with less fear and more fun, with less constraint and more
community support. Think creatively and critically about the kinds of
technologies you want to make and support. Learn to choose and use
tools, languages, and platforms that match your goals and ethics. Create
or join communities of practice that feel supportive and generative.</p>
</section>
<section
id="formative-a-critical-field-guide-for-working-with-machine-learning-datasets-and-inclusive-datasets-research-guide"
class="level3">
<h3>FORMATIVE: <em>A Critical Field Guide for Working with Machine
Learning Datasets</em> and <em>Inclusive Datasets Research
Guide</em></h3>
<!-- "A Critical Field Guide for Working with Machine Learning Datasets" offers practical guidance for conscientious dataset stewardship. It combines critical AI theories and technical data science concepts, explained in accessible language. It addresses journalists, students, scholars, activists, artists, and anyone starting to work with existing machine learning datasets, in the form of an instructional guidebook that combines approachable techniques with critical thinking questions, at the point when they are choosing, using, and maintaining datasets as the foundation for machine learning tasks. It is paired with the "Inclusive Datasets Research Guide," an online resource written for USC Libraries, which addresses a diverse student population who are also beginning to work with datasets.  -->
<p>Datasets provide the foundation for all of the large-scale machine
learning systems we encounter today, and they are increasingly part of
many other research fields and daily life. Many technical guides exist
for learning to work with datasets, and much scholarship has emerged to
study datasets critically <span class="citation"
data-cites="corryCriticalDatasetStudies gillespieCriticalAlgorithmStudies2015">(Corry
et al., n.d.; Gillespie and Seaver 2015)</span>. Yet no guides attempt
to combine technical and critical approaches comprehensively. Every
dataset is partial, imperfect, and historically and socially contingent
— yet the abundance of [problematic datasets and models] shows how
little attention is given to these critical concerns in typical use.</p>
<p><em>A Critical Field Guide for Working with Machine Learning
Datasets</em> helps navigate the complexity of working with giant
datasets. Its accessible tone and zero assumed knowledge support direct
use by practitioners of all stripes — activists, artists, journalists,
scholars, students — anyone who is interacting with datasets in the wild
and wants to use them in their work, while being mindful of their
impacts. Developed with Kate Crawford and Mike Ananny, as part of their
research team Knowing Machines, the field guide discusses parts and
types of datasets, how they are transformed, why bias cannot be
eliminated, and questions to ask at every stage of the dataset
lifecycle. Importantly, it shares benefits of working critically with
datasets when (on the surface) it may seem just as easy not to.</p>
<p>The <em>Inclusive Datasets Research Guide</em> is an interactive
digital guide for academic researchers working with datasets, that
supports them with an overview of key concepts and considerations for
working with datasets, as well as providing tools and software, books
and tutorials, and recommendations for thinking inclusively. Like the
Critical Field Guide, the Inclusive Datasets Research Guide focuses on a
blend of technical and critical decisions that arise when working with
datasets. Because this guide is aimed at students and teachers, the
format is brief collections of resources rather than conceptual
deep-dives. The guide appears on the USC Libraries’ website along with
its other research guides on many topics.</p>
<p>Developed by a team at USC Libraries, with the support of a grant
from the USC Office of Research, this research guide was written as part
of a grant to acquire core research datasets to support areas of inquiry
by USC researchers into arts, humanities, and machine learning. I was
recruited to provide interdisciplinary perspective on inclusive
approaches to machine learning, and I joined a team including a chief
library technologist, data science graduate students, special
collections librarians, a research communications specialist, and a
multimedia digital humanities specialist. We conducted 18 interviews
with faculty across campus who worked with datasets in order to develop
an internal rubric to support collection development. Through this
process, we found that the need was less for dataset acquisition,
because researchers did not look to libraries for their datasets but of
course had access to many elsewhere. Still, the rubric we developed was
utilized to acquire approximately 50 collections identified for being
more accessible, inclusive, ‘datafiable’, and meaningfully engaged.
Instead, we found the need existed for more curated resources and more
training on how to select and use datasets critically, while remaining
mindful of their origins and impacts — which led to the expanded aim of
the grant and the development of the <em>Inclusive Datasets Research
Guide</em></p>
<p>Both the Critical Field Guide and the Inclusive Datasets Research
Guide reflect on the stakes of datasets and the human choices they
relies on. Reframing the information in two different forms shows that
it can be more effective in different contexts, depending on the
audiences and the rhetorical tone they require. Both works are examples
of how concepts and processes researched in the <em>Intersectional AI
Toolkit</em> (below) can be reworked for new institutional contexts.
Adapting the Toolkit to new audiences in library science, data science,
and the social sciences posed interesting challenges that both expanded
and refined the work. It required the ideas be scaled up and applied,
and sometimes renegotiated until their rewordings no longer felt like
watering down. So much of [the work] I am still learning, is about
[people where they are][which means remembering that I have as much or
more to learn from others than the other way around.] In each project, I
got to learn how another field has addressed the problems of knowledge
organization and bias, historically and in the present. Library
scientists, of course, have at least a century of practice considering
questions of how to categorize, curate, and archive. Social scientists
have been asking how and what to measure for just as long. None of this
is perfect, either, but learning from each institution, and combining
thse with what machine learning is trying to ask, helps me understand
better how we got where we are today. Combining these with what other
intersectional practices may already understand helps me understand
better what each domain might learn from the other.</p>
<p>OBJECTIVES: Through the <em>Critical Field Guide for Working with
Machine Learning Datasets</em> and the <em>Inclusive Datasets Research
Guide</em>, understand the importance of working critically with
datasets as part of any machine learning practice. Identify the parts,
types, and functions of datasets as you encounter them. Determine
whether a particular dataset is a good fit for your project by asking
understanding critical questions to ask at each phase of the dataset
lifecycle. [Work with the communities impacted by your research to
create strategies for addressing potential harms in the datasets you
utilize.]</p>
</section>
<section id="systems-the-intersectional-ai-toolkit" class="level3">
<h3>SYSTEMS: <em>The Intersectional AI Toolkit</em></h3>
<!-- Both of these texts apply concepts from the "Intersectional AI Toolkit," which argues that anyone should be able to understand what AI is and help shape what AI ought to be. The Toolkit's co-authored zines are accessible guides to both AI and intersectionality. They find common vocabularies to connect diverse communities around AI's urgent questions. Its online resources learn from legacies of queer, feminist, antiracist, anticolonialist, and antiablest theories, ethics, and tactics, showing how established but marginalized tactics are necessary for reimagining more critical and ethical machine learning. The Toolkit addresses anyone who wants to understand the automated systems that impact them by using public workshops, zines, and digital resources in order to describe key concepts and processes of machine learning through critical lenses.  -->
<p>The <em>Intersectional AI Toolkit</em> argues that anyone should be
able to understand AI and help shape its futures. Through collaborative
sine-making workshops, it aims to find common vocabularies to connect
diverse communities around AI’s urgent questions. It clarifies, without
math or jargon, the inner workings of AI systems and the ways in which
they operate always as sociotechnical systems. The Toolkit celebrates
intersectional work done by many other researchers and artists working
to address these issues in interdisciplinary fields; and it gathers and
synthesizes legacies of anti-racist, queer, transfeminist, neurodiverse,
anti-ableist theories, ethics, and tactics that can contribute valuable
perspective. Its three formats allow for multiple entry points: The
digital wiki offers a forum for others to discuss and expand upon its
topics. The collection of printed zines share AI topics at a concise,
approachable scale. And the in-person and hybrid-online workshops invite
multiple communities to participate directly in the systems that impact
them.</p>
<p>Selecting the toolkit format was a key consideration of the
development process for the <em>Intersectional AI Toolkit</em>. The
toolkit form taken up here was first modeled after Ahmed’s ‘Killjoy
Survival Kit’ <span class="citation"
data-cites="ahmedLivingFeministLife2017">(Ahmed 2017)</span>.<span
class="sidenote-wrapper"><label for="sn-0" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-0" class="margin-toggle"/><span
class="sidenote">Ahmed says in <em>Living a Feminist Life</em> that the
killjoy survival kit should contain books, things, tools, time, life,
permission notes, other killjoys, humor, feelings, bodies, and your own
survival kit.<br />
<br />
</span></span>. The term ‘toolkit’ was thoroughly contested — too
instrumental and object-oriented — but settled upon after nothing else
quite suited. Not compendium or catalogue or care package, not index or
hub or gazetteer, not manifesto or knapsack or portal. The technologies
used went through many iterations, from git repo to wiki to self-hosted
hybrid back to repo again, in search of a platform that would facilitate
guest user access without heavy onboarding, track edits, and adapt to
multimedia zine forms. I am still remaking the work and searching for
the perfect form. I suspect I will have to create it, and it will
continue to change. In its various iterations, the Toolkit has grown
into eleven zine-making workshops, compiled into eight printed zines,
plus [xxx][eight][online topic pages]. Work on the Toolkit also resulted
in the two related datasets projects, which reflected back to inform the
Toolkit. Citizen data researcher Jennifer Gabrys says toolkits “provide
instructions not just for assembly and use but also for attending to the
social and political ramifications of digital devices.” She says they
are spaces of “instruction, contingency, action, and alternative
engagement” <span class="citation"
data-cites="gabrysHowThingsSensors2019">(Gabrys 2019)</span>. As such,
the <em>Intersectional AI Toolkit</em> hopes to provide resources and
access points for engaging differently with machine learning systems in
non-intimidating ways that connect different audiences.</p>
<p>OBJECTIVES: Through the Intersectional AI Toolkit, the need for
plural perspectives on AI systems. Understand key terminology related to
machine learning and to intersectionality. Share perspectives on the
impact of emerging technology as it relates to you. Choose critically
which AI tools and resources you will engage and how.</p>
<!--  Mattern: [@matternUnboxingToolkit2021] [Anthropologist Shannon Mattern details the many complex [lives] of 'kits', which can act as stop gaps for necessary infrastructure (bug out bags, refugee kits) or as "tools of engagement, as methods of inclusion, for broader communities" (rape kits)] -->
</section>
<section id="interstitial-portals-tactical-refusals" class="level3">
<h3>*: <em>Interstitial Portals &amp; Tactical Refusals</em></h3>
<!-- As interstices among these three texts, a collection of five short lyric essays imagine dialogues with five 20th century artists, asking how the artists' analog material practices might act as pre-responses to the contemporary digital concerns raised across *Coding.Care*. "Codes for (Un)Raveling," "Codes for (Un)Limiting, "Codes for (Un)Forming," "Codes for (Un)Living," and "Codes for (Un)Knowing" approach the lived experience of an algorithmic era from oblique angles. Unlike the other texts, the tone of the "Codes" essays addresses nonpractitioners on a more affective, aesthetic register, meant for reflection on the impact of sociotechnical systems as they entangle with individuals and marginalized groups.  -->
<ul>
<li><a href="unlimiting.html">(Un)Limiting</a>: Rebecca Horn, constraint
and COVID art</li>
<li><a href="unraveling.html">(Un)Raveling</a>: Sonya Rapoport, fiber
art and computation</li>
<li><a href="unforming.html">(Un)Forming</a>: VALIE EXPORT, glitch
feminism and broken machines</li>
<li><a href="unliving.html">(Un)Living</a>: On Kawara, dailiness, death,
and data</li>
<li><a href="unknowing.html">(Un)Knowing</a>: Pipilotti Rist, black
boxes and trauma</li>
</ul>
<p>Michel de Montaigne called the essay form a ‘trial’ or ‘attempt’.
These interstitial essays are attempts to speak in the nearbyness of
<em>Coding.Care</em>. They are trials, in the sense of struggles, to get
closer to the core of the creature by sneaking between its ribs. An
oblique strategy, they glance against logical modes of critical analysis
or direct address, in order to become the [thing] and probe the [thing]
and interrupt the [thing] [simultaneously].</p>
<p>As an alternate take on “bias” (because bias cannot be “optimized”
out of systems), these are bias cuts moving diagonally or diffractively
across the warp and weft of the fabric of the other texts here. Cutting
and sewing on the bias puts fabric in tension, making garments that take
the shape of the bodies they surround. Bias cuts are ways of working
with and against materials, acknowledging their limits and not resolving
them to right angles. Thus, these essays sustain the research tensions
of <em>Coding.Care</em>, unfurling the questions in the materials rather
than folding them away.</p>
<p>Locating (and writing in) “a correspondence, not an assemblage,” the
essays join together by “living with” concepts <span class="citation"
data-cites="ingoldLifeLines2015">(Ingold 2015)</span>. They are portals
to a co-existing “past-present-future” <span class="citation"
data-cites="olufemiExperimentsImaginingOtherwise2021">(Olufemi
2021)</span> for exploring our relationships with systems differently
and intimately, in which “the past is not lost, however, but rather a
space of potential” <span class="citation"
data-cites="chunDiscriminatingDataCorrelation2021">(Chun 2021)</span>.
[This is the threading together of nearbyness.]</p>
<blockquote>
<p>“the future is not in front of us, it is everywhere simultaneously:
multidirectional, variant, spontaneous. We only have to <em>turn
around</em>. Relational solidarities, even in their failure, reveal the
plurality of the future-present, help us to see through the impasse,
help temporarily eschew what is stagnant, help build and then prepare to
shatter the many windows of the here and now.” <span class="citation"
data-cites="olufemiExperimentsImaginingOtherwise2021">(Olufemi
2021)</span>
<!-- >"The imagination is central to the cultural production of revolutionary movements; its primary role is to signal *what could be. What could be* is a lingistic stand-in for a set of political, social and cultural demands, strategic aims, revolutionary longings. As such, it resists singular definition."[@olufemiExperimentsImaginingOtherwise2021]   --></p>
</blockquote>
<p>As part of locating correspondences, the essays also use
correspondance as a form, relying on epistolary address to conjure up
analogue antecedents to the digital media discussed in other sections of
<em>Coding.Care</em>. I read the works of several 20th century media
artists as pre-responses to automated systems. Their wide range of
practices — from minimalist daily rituals to queer feminist body art and
performance — show how we have always—already been living in, talking
about, performing with the questions amplified by automated systems,
classification, and datification. Their works offer a breadth of
artistic possibilities for reconsidering our relationships with
computational systems — and these responses were already being
established in parallel to the development of those systems. They help
me reimagine how I want to respond now.</p>
<p>The essay form is a kind of embodied processing that moves the
[corpus through the corpus], a reckoning in throat and gut that pairs
bodily processing with computational processing. These interstitial
essays serve, as queer scholar KJ Cerankowski writes, “to let this book
be the crisis rather than about the crisis or crises, rather, a
plurality of traumas and pains felt collectively and individually” <span
class="citation"
data-cites="cerankowskiSutureTraumaTrans2021">(Cerankowski 2021)</span>.
Long traditions of artistic and literary outliers have maintained the
need for such forms, like autotheory and lyric essay, which bridge
aesthetic, personal, and political concerns. From these traditions, I am
interested both in the constitutive act of form-making (as
prefiguration) and in the reconsitituion of critical forms into poetic,
personalized, or approachable forms <span class="citation"
data-cites="fournierAutotheoryFeministPractice2021">(Fournier
2021)</span>. <!-- abolition --></p>
<!-- >"In projects like Theory Boner, artists and writers and curators come together to configure critical theory as something that must be processed and transmuted through the body and is very physical and even sexual in its effects on us; like [Hazel] Meyer's No Theory No Cry, [these works] make space for a way of relating to theory that is embodied, affective, and more directly relevant to the lives of queer and gender-nonconforming feminist artists, activists, and students. [@fournierAutotheoryFeministPractice2021] >"constituting life through the act of writing—rather than as expressive (describing a life that exists prior to the act of writing about it)." [@fournierAutotheoryFeministPractice2021]
-->
<!-- My favorite pieces of writing all feel permissive. In the moment of reading, I feel more alive with the realizataion, "it's allowed to write this way?" And then, the crash: "But who is allowed to write this way? Maybe only after certain requirements are met." I am never sure I am allowed, which is why I always want to try when I am lucky enough to feel supported to try, in hope that my doing so edges open a little more space for others and for othered writing forms. -->
<!-- [XXX][more?] -->
<!-- >Willis locates in the postcinematic "the imbrication of selves and systems, of agency alongside generative processes" "Our understanding of space [and time] shifts as it is coded computationally" "our viewing is becoming a process of navigating and our stories are the ones that we tell of our own experiences of traversal and exploration." "toward time as presence, performance and exchange. This is an era of acceleration, but also of duration, of elastic time flows and of layering;" "Practice becomes participatory and collaborative, manoeuvring through new conceptions of the spatial and temporal. [@willisFastForwardFuture2016] -->
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-abbateCodingNotEmpowerment2021" class="csl-entry"
role="listitem">
Abbate, Janet. 2021. <span>“Coding Is Not Empowerment.”</span> In
<em>Your Computer Is on Fire</em>, edited by Thomas S. Mullaney,
Benjamin Peters, Mar Hicks, and Kavita Philip, 253–72. The MIT Press. <a
href="https://doi.org/10.7551/mitpress/10993.003.0018">https://doi.org/10.7551/mitpress/10993.003.0018</a>.
</div>
<div id="ref-ahmedLivingFeministLife2017" class="csl-entry"
role="listitem">
Ahmed, Sara. 2017. <em>Living a Feminist Life</em>. Durham: Duke
University Press.
</div>
<div id="ref-ainowinstituteLaborThatMakes" class="csl-entry"
role="listitem">
AI Now Institute, dir. n.d. <em>The Labor That Makes AI
<span>“Magic”</span> | Lilly Irani | AI Now 2016</em>. Accessed
September 2, 2018. <a
href="https://www.youtube.com/watch?time_continue=68&amp;v=5vXqpc2jCKs">https://www.youtube.com/watch?time_continue=68&amp;v=5vXqpc2jCKs</a>.
</div>
<div id="ref-AlwaysalreadyprogrammingMda" class="csl-entry"
role="listitem">
<span>“Always-Already-Programming.md.”</span> n.d. Gist. Accessed July
22, 2023. <a
href="https://gist.github.com/melaniehoff/95ca90df7ca47761dc3d3d58fead22d4">https://gist.github.com/melaniehoff/95ca90df7ca47761dc3d3d58fead22d4</a>.
</div>
<div id="ref-amaroBlackTechnicalObject2022" class="csl-entry"
role="listitem">
Amaro, Ramon. 2022. <em>The Black technical object: on machine learning
and the aspiration of Black being</em>. London: Sternberg Press.
</div>
<div id="ref-amooreCloudEthicsAlgorithms2020" class="csl-entry"
role="listitem">
Amoore, Louise. 2020. <em>Cloud Ethics: Algorithms and the Attributes of
Ourselves and Others</em>. <a
href="https://doi.org/10.1215/9781478009276">https://doi.org/10.1215/9781478009276</a>.
</div>
<div id="ref-AntiRacistHCINotes" class="csl-entry" role="listitem">
<span>“Anti-Racist HCI: Notes on an Emerging Critical Technical Practice
| Extended Abstracts of the 2022 CHI Conference on Human Factors in
Computing Systems.”</span> n.d. Accessed July 5, 2022. <a
href="https://dl.acm.org/doi/10.1145/3491101.3516382">https://dl.acm.org/doi/10.1145/3491101.3516382</a>.
</div>
<div id="ref-artistBlackGooeyUniverse" class="csl-entry"
role="listitem">
Artist, American. n.d. <span>“Black Gooey Universe.”</span> Unbag.
Accessed February 19, 2021. <a
href="https://unbag.net/end/black-gooey-universe">https://unbag.net/end/black-gooey-universe</a>.
</div>
<div id="ref-banksRaceRhetoricTechnology2006" class="csl-entry"
role="listitem">
Banks, Adam J. 2006. <em>Race, Rhetoric, and Technology: Searching for
Higher Ground</em>. Routledge.
</div>
<div id="ref-benderDangersStochasticParrots2021" class="csl-entry"
role="listitem">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021. <span>“On the Dangers of Stochastic Parrots: Can
Language Models Be Too Big?”</span> In <em>Proceedings of the 2021 ACM
Conference on Fairness, Accountability, and Transparency</em>, 610–23.
FAccT ’21. New York, NY, USA: Association for Computing Machinery. <a
href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-benjaminRaceTechnologyAbolitionist2019" class="csl-entry"
role="listitem">
Benjamin, Ruha. 2019. <em>Race After Technology: Abolitionist Tools for
the New Jim Code</em>. 1 edition. Medford, MA: Polity.
</div>
<div id="ref-browneDarkMattersSurveillance2015" class="csl-entry"
role="listitem">
Browne, Simone. 2015. <em>Dark matters: on the surveillance of
blackness</em>. Durham, [North Carolina] ; Duke University Press.
</div>
<div id="ref-buolamwiniAJLALGORITHMICJUSTICE" class="csl-entry"
role="listitem">
Buolamwini, Joy. n.d. <span>“AJL -ALGORITHMIC JUSTICE LEAGUE.”</span>
AJL -ALGORITHMIC JUSTICE LEAGUE. Accessed December 3, 2018. <a
href="https://www.ajlunited.org/">https://www.ajlunited.org/</a>.
</div>
<div id="ref-buolamwiniGenderShadesIntersectional2018" class="csl-entry"
role="listitem">
Buolamwini, Joy, and Timnit Gebru. 2018. <span>“Gender Shades:
Intersectional Accuracy Disparities in Commercial Gender
Classification.”</span> In <em>Proceedings of the 1st Conference on
Fairness, Accountability and Transparency</em>, 77–91. PMLR. <a
href="https://proceedings.mlr.press/v81/buolamwini18a.html">https://proceedings.mlr.press/v81/buolamwini18a.html</a>.
</div>
<div id="ref-calvinoNumbersDarkOther1976" class="csl-entry"
role="listitem">
Calvino, Italo. 1976. <em>Numbers in the dark: and other stories</em>.
Edited by Tim Parks. New York: Pantheon Books.
</div>
<div id="ref-CAREPrinciplesIndigenousa" class="csl-entry"
role="listitem">
<span>“CARE Principles of Indigenous Data Governance.”</span> n.d.
Global Indigenous Data Alliance. Accessed March 14, 2022. <a
href="https://www.gida-global.org/care">https://www.gida-global.org/care</a>.
</div>
<div id="ref-cerankowskiSutureTraumaTrans2021" class="csl-entry"
role="listitem">
Cerankowski, K. J. 2021. <em>Suture: Trauma and Trans Becoming</em>. 1st
ed. Santa Barbara: Punctum Books.
</div>
<div id="ref-chakravarttyVirtualRoundtableDecolonial2018"
class="csl-entry" role="listitem">
Chakravartty, Paula, and Mara Mills. 2018. <span>“Virtual Roundtable on
<span>‘Decolonial Computing’</span>.”</span> <em>Catalyst: Feminism,
Theory, Technoscience</em> 4 (2): 1–4. <a
href="https://doi.org/10.28968/cftt.v4i2.29588">https://doi.org/10.28968/cftt.v4i2.29588</a>.
</div>
<div id="ref-chunDiscriminatingDataCorrelation2021" class="csl-entry"
role="listitem">
Chun, Wendy Hui Kyong. 2021. <em>Discriminating Data: Correlation,
Neighborhoods, and the New Politics of Recognition</em>. The MIT Press.
<a
href="https://doi.org/10.7551/mitpress/14050.001.0001">https://doi.org/10.7551/mitpress/14050.001.0001</a>.
</div>
<div id="ref-cistonIntersectionalAIEssential2019" class="csl-entry"
role="listitem">
Ciston, Sarah. 2019. <span>“Intersectional AI Is Essential: Polyvocal,
Multimodal, Experimental Methods to Save Artificial
Intelligence.”</span> <em>Journal of Science and Technology of the
Arts</em> 11 (2): 3–8. <a
href="https://doi.org/10.7559/citarj.v11i2.665">https://doi.org/10.7559/citarj.v11i2.665</a>.
</div>
<div id="ref-cooperIntersectionality2016" class="csl-entry"
role="listitem">
Cooper, Brittney. 2016. <span>“Intersectionality.”</span> In <em>The
Oxford Handbook of Feminist Theory</em>, edited by Lisa Disch and Mary
Hawkesworth. Vol. 1. Oxford University Press. <a
href="https://doi.org/10.1093/oxfordhb/9780199328581.013.20">https://doi.org/10.1093/oxfordhb/9780199328581.013.20</a>.
</div>
<div id="ref-corryCriticalDatasetStudies" class="csl-entry"
role="listitem">
Corry, Frances, Edward B. Kang, Hamsini Sridharan, Sasha Luccioni, Mike
Ananny, and Kate Crawford. n.d. <span>“Critical Dataset Studies Reading
List.”</span> Knowing Machines. <a
href="https://knowingmachines.org/reading-list">https://knowingmachines.org/reading-list</a>.
</div>
<div id="ref-crawfordAtlasAIPower2021" class="csl-entry"
role="listitem">
Crawford, Kate. 2021. <em>Atlas of AI: Power, Politics, and the
Planetary Costs of Artificial Intelligence</em>. New Haven: Yale
University Press.
</div>
<div id="ref-crenshawDemarginalizingIntersectionRace1989"
class="csl-entry" role="listitem">
Crenshaw, Kimberle. 1989. <span>“Demarginalizing the Intersection of
Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine,
Feminist Theory and Antiracist Politics.”</span> <em>University of
Chicago Legal Forum</em> 1989: 139–68. <a
href="https://heinonline.org/HOL/P?h=hein.journals/uchclf1989&amp;i=143">https://heinonline.org/HOL/P?h=hein.journals/uchclf1989&amp;i=143</a>.
</div>
<div id="ref-dunbar-hesterHackingDiversityPolitics2019"
class="csl-entry" role="listitem">
Dunbar-Hester, Christina. 2019. <em>Hacking Diversity: The Politics of
Inclusion in Open Technology Cultures</em>. Princeton, New Jersey:
Princeton University Press. <a
href="https://doi.org/10.2307/j.ctvhrd181">https://doi.org/10.2307/j.ctvhrd181</a>.
</div>
<div id="ref-escofferyAncestralIntelligenceAI2023" class="csl-entry"
role="listitem">
Escoffery, Aymar Jèan. 2023. <span>“Ancestral Intelligence: The AI We
Need.”</span> <em>Commonplace</em>, October. <a
href="https://doi.org/10.21428/6ffd8432.6bf7b4ae">https://doi.org/10.21428/6ffd8432.6bf7b4ae</a>.
</div>
<div id="ref-fournierAutotheoryFeministPractice2021" class="csl-entry"
role="listitem">
Fournier, Lauren. 2021. <em>Autotheory as Feminist Practice in Art,
Writing, and Criticism</em>. <a
href="http://direct.mit.edu/books/book/5028/Autotheory-as-Feminist-Practice-in-Art-Writing-and">http://direct.mit.edu/books/book/5028/Autotheory-as-Feminist-Practice-in-Art-Writing-and</a>.
</div>
<div id="ref-franklinRealWorldTechnology2004" class="csl-entry"
role="listitem">
Franklin, Ursula M. 2004. <em>The Real World of Technology</em>. Rev.
ed. CBC Massey Lectures Series. Toronto, Ont. : Berkeley, CA: House of
Anansi Press ; Distributed in the United States by Publishers Group
West.
</div>
<div id="ref-gabrysHowThingsSensors2019" class="csl-entry"
role="listitem">
Gabrys, Jennifer. 2019. <em>How to Do Things with Sensors</em>.
University of Minnesota Press. <a
href="https://doi.org/10.5749/j.ctvpbnq7k">https://doi.org/10.5749/j.ctvpbnq7k</a>.
</div>
<div id="ref-gebruDrTimnitGebru2021" class="csl-entry" role="listitem">
Gebru, Timnit, dir. 2021. <em>Dr. Timnit Gebru: Hierarchy of Knowledge
in Machine Learning &amp; Related Fields and Its Consequences -
YouTube</em>. Spellman College. <a
href="https://www.youtube.com/watch?v=OL3DowBM9uc">https://www.youtube.com/watch?v=OL3DowBM9uc</a>.
</div>
<div id="ref-gillespieCriticalAlgorithmStudies2015" class="csl-entry"
role="listitem">
Gillespie, Tarleton, and Nick Seaver. 2015. <span>“Critical Algorithm
Studies: A Reading List.”</span> <em>Social Media Collective</em>
(blog). November 5, 2015. <a
href="https://socialmediacollective.org/reading-lists/critical-algorithm-studies/">https://socialmediacollective.org/reading-lists/critical-algorithm-studies/</a>.
</div>
<div id="ref-goodmanSecretLifeAlgorithms" class="csl-entry"
role="listitem">
Goodman, Andrew. n.d. <span>“The Secret Life of Algorithms: Speculation
on Queered Futures of Neurodiverse Analgorithmic Feeling and
Consciousness,”</span> 22.
</div>
<div id="ref-hakopianInstituteOtherIntelligences2022" class="csl-entry"
role="listitem">
Hakopian, Mashinka Firunts. 2022. <em>The Institute for Other
Intelligences</em>. Edited by Anuradha Vikram and Ana Iwataki. X
Artists’ Books.
</div>
<div id="ref-hamraieCripTechnoscienceManifesto2019a" class="csl-entry"
role="listitem">
Hamraie, Aimi, and Kelly Fritsch. 2019. <span>“Crip Technoscience
Manifesto.”</span> <em>Catalyst: Feminism, Theory, Technoscience</em> 5
(1): 1–33. <a
href="https://doi.org/10.28968/cftt.v5i1.29607">https://doi.org/10.28968/cftt.v5i1.29607</a>.
</div>
<div id="ref-haoNewVisionArtificial2022" class="csl-entry"
role="listitem">
Hao, Karen. 2022. <span>“A New Vision of Artificial Intelligence for the
People.”</span> <em>MIT Technology Review</em>, April 22, 2022. <a
href="https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/">https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/</a>.
</div>
<div id="ref-hicksSexismFeatureNot2021" class="csl-entry"
role="listitem">
Hicks, Mar. 2021. <span>“Sexism Is a Feature, Not a Bug.”</span> In
<em>Your Computer Is on Fire</em>, edited by Thomas S. Mullaney,
Benjamin Peters, Mar Hicks, and Kavita Philip, 135–58. The MIT Press. <a
href="https://doi.org/10.7551/mitpress/10993.003.0011">https://doi.org/10.7551/mitpress/10993.003.0011</a>.
</div>
<div id="ref-hooksTeachingTransgressEducation1994" class="csl-entry"
role="listitem">
hooks, bell. 1994. <em>Teaching to Transgress: Education as the Practice
of Freedom</em>. New York: Routledge.
</div>
<div id="ref-INDIGENOUSAI" class="csl-entry" role="listitem">
<span>“INDIGENOUS AI.”</span> n.d. <em>INDIGENOUS AI</em> (blog).
Accessed April 25, 2022. <a
href="https://www.indigenous-ai.net/">https://www.indigenous-ai.net/</a>.
</div>
<div id="ref-ingoldLifeLines2015" class="csl-entry" role="listitem">
Ingold, Tim. 2015. <em>The Life of Lines</em>. London ; New York:
Routledge.
</div>
<div id="ref-keelingQueerOS2014" class="csl-entry" role="listitem">
Keeling, Kara. -01-22 2014. <span>“Queer OS.”</span> <em>Cinema
Journal</em> 53 (2): 152–57. <a
href="https://doi.org/10.1353/cj.2014.0004">https://doi.org/10.1353/cj.2014.0004</a>.
</div>
<div id="ref-klipphahn-kargeQueereKIComingout" class="csl-entry"
role="listitem">
Klipphahn-Karge, Michael, and Ann-Kathrin Koster. n.d. <span>“Queere KI
- Zum Coming-out smarter Maschinen.”</span>
</div>
<div id="ref-klumbyteCriticalToolsMachine2022a" class="csl-entry"
role="listitem">
Klumbytė, Goda, Claude Draude, and Alex S. Taylor. 2022. <span>“Critical
Tools for Machine Learning: Working with Intersectional Critical
Concepts in Machine Learning Systems Design.”</span> In <em>Proceedings
of the 2022 ACM Conference on Fairness, Accountability, and
Transparency</em>, 1528–41. FAccT ’22. New York, NY, USA: Association
for Computing Machinery. <a
href="https://doi.org/10.1145/3531146.3533207">https://doi.org/10.1145/3531146.3533207</a>.
</div>
<div id="ref-lovelessHowMakeArt2019" class="csl-entry" role="listitem">
Loveless, Natalie. 2019. <em>How to Make Art at the End of the World: A
Manifesto for Research-Creation</em>. Durham: Duke University Press
Books.
</div>
<div id="ref-marinoCriticalCodeStudies2020a" class="csl-entry"
role="listitem">
Marino, Mark C. 2020. <em>Critical Code Studies</em>. Software Studies.
Cambridge, Massachusetts: The MIT Press.
</div>
<div id="ref-nakamuraIndigenousCircuitsNavajo2014" class="csl-entry"
role="listitem">
Nakamura, Lisa. 2014. <span>“Indigenous Circuits: Navajo Women and the
Racialization of Early Electronic Manufacture.”</span> <em>American
Quarterly</em> 66 (4): 919–41. <a
href="https://muse.jhu.edu/pub/1/article/563663">https://muse.jhu.edu/pub/1/article/563663</a>.
</div>
<div id="ref-nakeThereShouldBe1971" class="csl-entry" role="listitem">
Nake, Frieder. 1971. <span>“There Should Be No Computer Art.”</span>
<em>Bulletin of the Computer Arts Society</em>, October.
</div>
<div id="ref-nardiSmallMatterProgramming1993" class="csl-entry"
role="listitem">
Nardi, Bonnie A. 1993. <em>A Small Matter of Programming: Perspectives
on End User Computing</em>. <a
href="https://doi.org/10.7551/mitpress/1020.001.0001">https://doi.org/10.7551/mitpress/1020.001.0001</a>.
</div>
<div id="ref-neddenBiometrieGetestetMillionen2017" class="csl-entry"
role="listitem">
Nedden, Christina zur, and Ariana Dongus. 2017. <span>“Biometrie:
Getestet an Millionen Unfreiwilligen.”</span> <em>Die Zeit</em>,
December 17, 2017. <a
href="https://www.zeit.de/digital/datenschutz/2017-12/biometrie-fluechtlinge-cpams-iris-erkennung-zwang">https://www.zeit.de/digital/datenschutz/2017-12/biometrie-fluechtlinge-cpams-iris-erkennung-zwang</a>.
</div>
<div id="ref-nobleAlgorithmsOppressionHow2018" class="csl-entry"
role="listitem">
Noble, Safiya Umoja. 2018. <em>Algorithms of Oppression : How Search
Engines Reinforce Racism</em>. New York: NYU Press. <a
href="http://search.ebscohost.com/login.aspx?direct=true&amp;db=nlebk&amp;AN=1497317&amp;authtype=sso&amp;custid=s8983984">http://search.ebscohost.com/login.aspx?direct=true&amp;db=nlebk&amp;AN=1497317&amp;authtype=sso&amp;custid=s8983984</a>.
</div>
<div id="ref-olufemiExperimentsImaginingOtherwise2021" class="csl-entry"
role="listitem">
Olufemi, Lola. 2021. <em>Experiments in Imagining Otherwise</em>. Hajar
Press.
</div>
<div id="ref-ovalleFactoringMatrixDomination2023a" class="csl-entry"
role="listitem">
Ovalle, Anaelia, Arjun Subramonian, Vagrant Gautam, Gilbert Gee, and
Kai-Wei Chang. 2023. <span>“Factoring the Matrix of Domination: A
Critical Review and Reimagination of Intersectionality in AI
Fairness.”</span> arXiv. <a
href="https://doi.org/10.48550/arXiv.2303.17555">https://doi.org/10.48550/arXiv.2303.17555</a>.
</div>
<div id="ref-raleyCriticalAIField2023" class="csl-entry"
role="listitem">
Raley, Rita, and Jennifer Rhee. 2023. <span>“Critical AI: A Field in
Formation.”</span> <em>American Literature</em>, March, 10575021. <a
href="https://doi.org/10.1215/00029831-10575021">https://doi.org/10.1215/00029831-10575021</a>.
</div>
<div id="ref-ravalAgendaDecolonizingData2019" class="csl-entry"
role="listitem">
Raval, Noopur. 2019. <span>“An Agenda for Decolonizing Data
Science.”</span> <em>spheres: Journal for Digital Cultures</em>, no. 5:
1–6. <a
href="https://doi.org/10.25969/mediarep/13499">https://doi.org/10.25969/mediarep/13499</a>.
</div>
<div id="ref-rightsDecolonisingAITransfeminist2020a" class="csl-entry"
role="listitem">
Rights, Coding. 2020. <span>“Decolonising AI: A Transfeminist Approach
to Data and Social Justice.”</span> Medium. September 10, 2020. <a
href="https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96">https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96</a>.
</div>
<div id="ref-robertsCommercialContentModeration2016" class="csl-entry"
role="listitem">
Roberts, Sarah T. 2016. <span>“Commercial Content Moderation: Digital
Laborers’ Dirty Work.”</span> In <em>The intersectional Internet: race,
sex, class and culture online</em>, 147–60. Digital formations, vol.
105. New York: Peter Lang Publishing, Inc.
</div>
<div id="ref-sharmaManifestoBrokenMachine2020" class="csl-entry"
role="listitem">
Sharma, Sarah. 2020. <span>“A Manifesto for the Broken Machine.”</span>
<em>Camera Obscura: Feminism, Culture, and Media Studies</em> 35 (2
(104)): 171–79. <a
href="https://doi.org/10.1215/02705346-8359652">https://doi.org/10.1215/02705346-8359652</a>.
</div>
<div id="ref-sloaneParticipationNotDesign2022" class="csl-entry"
role="listitem">
Sloane, Mona, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022.
<span>“Participation Is Not a Design Fix for Machine Learning.”</span>
In <em>Equity and Access in Algorithms, Mechanisms, and
Optimization</em>, 1–6. EAAMO ’22. New York, NY, USA: Association for
Computing Machinery. <a
href="https://doi.org/10.1145/3551624.3555285">https://doi.org/10.1145/3551624.3555285</a>.
</div>
<div id="ref-veeCodingLiteracyHow2017" class="csl-entry"
role="listitem">
Vee, Annette. 2017. <em>Coding Literacy: How Computer Programming Is
Changing Writing</em>. <a
href="http://direct.mit.edu/books/book/3543/Coding-LiteracyHow-Computer-Programming-Is">http://direct.mit.edu/books/book/3543/Coding-LiteracyHow-Computer-Programming-Is</a>.
</div>
<div id="ref-willisFastForwardFuture2016" class="csl-entry"
role="listitem">
Willis, Holly. 2016. <em>Fast Forward: The Future(s) of the Cinematic
Arts</em>. Wallflower Press.
</div>
</div>
</section>
</section>
</article>
</body>
</html>

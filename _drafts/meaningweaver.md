---
# layout: post
permalink: meaningweaver
title: Meaning Weaver
nav_order: 95
---

nearbyness and phenomenological language modeling

>what would be a phenomenological (rather than stocastic) computational representation of language?

>"words encoding the bodies they cover. And despite everything the body remains." [@rankineCitizenAmericanLyric2014]

[When/how] did language become mathematical(ized), probabilistic, and spatial(ized)? 

This project is interested in where the acceleration we see requires reductions, in meaning and modes of representation: How did words become vectors—not just numbers but spatialized probabilities—reducing meaning to arrows in latent space? 
 
How do the technical choices that create numerical representations of word fragments (tokens) come to inform large generative text outputs? How do historical developments come to inform those technical choices?

Bernard Geoghegan, Adrian MacKenzie, Louise Amoore, Eve Sedgwick, 

Tokenization produces 'nearness' and 'similarity' (and thereby distance and difference) through statistical processes that claim to reflect real-world conditions. Even when they manage to depict shades of reality, rather than merely their own apparatus, much is lost. What is lost is nearbyness. Layered poetics of meaning. 


TOKENIZATION PROCESSES **CREATE/PRODUCE** NEARNESS THROUGH STATISTICAL PROCESSES THAT DO NOT NECESSARILY REFLECT REAL-WORLD CONDITIONS. EVEN WHEN THEY DO, MUCH IS LOST. WHAT IS LOST IS NEARBYNESS, LAYERS AND POETICS OF MEANING. LINGUISTIC CAPITALISM MAY NOT CARE ABOUT THIS, BUT I DO. 
They literally sort for the most frequent bytes, then pair them and sort for the most frequent of those, then pair those, then sort again and so on. Producing and grouping together, producing nearness. 

Code: sign, storage, transmission by Bernie Geoghean (but philanthropy not conceptually)

When did language become mathematical?
Not just numbers but numbers in space > vectors. 
Vectors, similarity proximity. 

hyper-models after hyperparameters

Paper/exhibition/

**Nearness vs nearbyness (paper) conclusion/pitch. Provocative to farther work.**

re Elea, the hope would be to understand "What does it mean for me today to use these systems, why does a certain feature/methodology come to exist, instantly matters to me. If I utilize this I must be aware of how the tech can even devoid of historical contexts its created from, how are the tech still ways they might propagate injustices and systems of power."

"Feelings are 'vectors'; for they feel what is there and transform it into what is here" (Whitehead 1978, 87). 
A vector describing anything that covers space. A vector is a way of describing transformation using space. But it is only one way. 

When did we begin using spatial metaphors? [What's his face linguist] would say since we had bodies in space. This was the first (problem?) But to describe those spatial relationships through an additional layer of abstraction, mathematical, and then statistical abstraction. (As Vladan was saying, the move from algorithmic (he means procedural) to statistical analysis (modeling)) is the move that allows another whole danger. 

Monte Carlo methods actually more Frequentist in approach than Bayesian, ironically. Do we today use a weird multi-headed hydra of bayes and frequentism/MC? "Multiheaded attention/multiheaded hydra"

Hydra Transformers. 

>"To talk about vectors was to talk about data in the abstract, being i ally vague about that data’s sources." [@seaverCareScaleDecorrelative2021a]
>"instead of talking about conflicts among values, Huron spoke of c relations among value vectors."
>"Even in technical use, vectorization is a tool for abstraction, for t forming ordinary tabular data into malleable orientations in multidimensional space (cf. Mackenzie 2017). Vector spaces are the symbolic terrain on which much of the labor of machine learning works, and they provide a widespread metaphorical language across the software industry. Startup founders describe their employees as vectors; venture capitalists describe the companies they fund as vectors; in ordinary conversation, engineers will describe unrelated things as “orthogonal” to each other."



Computational processing is mechanized reduction, converting only the kinds of information that can be ‘captured’ in numerical representation. Its knowing is not human knowing, though it answers to names like ‘learning’ and ‘understanding’ [1]. Its logics of classification (taxonomies, decision trees, probability) often evoke the same biases as the colonial, racializing logics from which they spring—and its reduction is what enables its accelerationist project.  

Here I use material 

As a question of scale, the project investigates the sociotechnical processes of machine learning models to understand, for example, how the technical choices that create numerical representations of word fragments will come to inform large-scale generative text outputs, as well as how historical developments came to inform those technical choices. How did language become probabilistic? How did words become vectors, reducing meaning to an arrow in latent space? 

This project has multiple trajectories: It looks historically, tracing the origins of the language model back to a 1947 memo from Warren Weaver, a cyberneticist bureaucrat. Statistical conceptions of language emerge alongside wartime aerial firing and weapons development, as well as eugenicists' racist beliefs about categorization. The idea takes hold in the cybernetics boom following WWII and connects to developments in cryptography, translation, linguistics, phonology, statistics and probability, cybernetics, taxonomy.

**It also arcs into transformative futures, mapping how these histories project into the present to shape computational conceptions of language and meaning. It imagines other possibilities for these conceptions through alternative metaphors and methods for language models.**


~~How did language become mathematical and probabilistic? That is, how did words become ‘word vectors,’ recasting meaning as an arrow in multidimensional latent space?~~

Computation is mechanized reduction, representing only the information that can be captured numerically. It answers to names like ‘learning’ and ‘understanding’, but its knowing is unlike humans’. [1] Its logics of classification (taxonomies, decision trees) often evoke the colonial, racializing logics from which they spring. [2]–[4] 


# Weaving "Universal" Meaning from Numbers

[//]: # "write it in style of Bell's *Undercurrents* with snippets of history described in essay with a personal narrative also weaving through"

**How did the idea become prominent that language, and its meaning, could be represented through numbers and computation? Temporarily setting aside whether or not this is a *good* idea, I am interested in the history of the idea. It emerges in prominence in the cybernetic boom just following the Second World War, with strands of thought that run much further back in time. It spans developments in cryptography, translation, linguistics, phonology, statistics and probability, cybernetics, taxonomy; with roots in wartime aerial firing and weapons development, eugenicists' racist beliefs about categorization. This work traces some of the thinkers, historical moments, and intellectual pivots** 

The concepts of "universal language" and of applying cryptographic methods towards language translation data at least back to Athanasius Kircher and Holy Roman Emperor Ferdinand III (and perhaps much further, from non-Western perspectives). However, it is a single memo written in 1947 by mathematician Warren Weaver that is credited with launching the field of "Machine Translation" and later Natural Language Processing. 

Most often, Weaver's name is found, if at all, behind Claude Shannon's in the highly influential model of communication that bears their names. But Shannon introduced the model in a 1948 single-authored paper, "A Mathematical Theory of Information," and Weaver wrote a short introduction to the paper for general audiences. Together these were republished in 1949 as a book titled *The Mathematical Theory of Information*. Katherine Hayles reports (in a footnote in [book?])on the nature of Weaver and Shannon's collaboration on the Shannon–Weaver model: 
>"According to Eric A. Weiss, Shannon told him in correspondence that Weaver put together the volume without consulting Shannon. Weiss wrote: 'Weaver was a big-shot scientific gatekeeper at the time; Shannon was a more or less nobody. Weaver took some notes ... or something by Shannon and turned it into the 1949 writing putting his name first and without really getting Shannon's consent. Shannon felt that Weaver had made a good explanation, this was one of Weaver's skills, and did not object seriously at the time' (Weiss to author, private communication)."

Who was Weaver? And why did his memo launch a thousand (or more) machine translations and the history a field? At various points, Weaver was a mathematics professor at University of Wisconsin and what would become CalTech, a director at the Rockefeller Foundation distributing funding for research in engineering and biological sciences [agriculture, genetics, and medicine], and researched weapons aiming for the army during WWII and headed their division on applied mathematics research in the same OSRD where the Manhattan Project was being developed. He appears in archives as a powerful correspondent and witness to developments in weapons, artificial intelligence, cybernetics, and [xxx]. He is pictured with [XXX] Lawrence (namesake of weapons[XXX?] research facility Lawrence Livermore Labs) in 1940 at one of the first meetings for the Manhattan Project. [XXX] writes to him 




From Athanasius Kircher's faulty attempts to decipher hieroglyphics () and early proposals for a "universal language" and work in cryptography (*Polygraphia Nova* 1663), 

How often the word "intuition" comes up is disturbing for a science that presents as the so-called rational antidote to human feeling. In CS textbooks, the term "intuition" seems to mean something between "common sense" or "hypothesis" — yet never in the literature are these intuitions checked by anything other than the notion "it just works" to get the desired results.

The inversion of finding the theory to fit the data, pattern seeking: 
>"machine learning can be understood as a function-finding operation." [@mackenzieMachineLearnersArchaeology2017]

**By function finding, machine learning seeks a description of a transformation required to turn input data to desired output data.**

>"learning is comprehensively understood in machine learning as finding a mathematical function that could have generated the data and optimizing the search for that function as much as possible." @mackenzieMachineLearnersArchaeology2017
>"the important point is that the notion of the learning machine sets in motion an ongoing diagonalization or sideways slippage that transforms the basic diagram of the linear model through substitutions of increasingly convoluted or nested operations." @mackenzieMachineLearnersArchaeology2017

All things are vectors (Whitehead 1960, 309). (via MacKenzie)

While a few of the most prominent names from eugenic "race science" and military projects have been stripped from buildings or removed from lecture posts, their methods and logics carry forward into the latest generative AI systems. Francis Galton, Ronald Fisher, Karl Pearson's, and others' racist, capitalist, militarizing worldviews are embedded into the way we think with numbers [and the way we numericalize everything] today. As statistics removes the names of Pearson, Fisher, and Galton, machine learning chugs on and science still measures the right to publish by their idea of "statistical significance." @claytonHowEugenicsShaped2020

Oft repeated “the meaning of a word can be inferred by the company it keeps” JR FIRTH. >>> 

WENDY CHUN Homophily

“Distributional hypothesis in semantics” words more similar will be used more often together
https://www.youtube.com/watch?v=oUpuABKoElw
JR Firth (1957)

GPT: SMASHWORDS is original BOOKCORPUS source
https://huggingface.co/datasets/bookcorpus
* Addressing "Documentation Debt" in Machine Learning Research: A Retrospective Datasheet for BookCorpus

approx 25% of OpenAI corpus was written by women [@kuntzWhoAuthorsInternet2023], and that's the biggest "minority" but consider all other missing datasets (Onuoha)

Reduces world to stereotypes [@HowAIReduces2023]

VOCABULARY VECTORIZING EMBEDDINGS
Pre-Training a vocab: “Typically the vocabulary is created from training data by retaining the most frequent N words in the source and target language." (https://machinetranslate.org/vocabulary) 
Literally an ordered list of token frequency > index.

The technique to turn language into numbers was originally used for data compression. Compression is usually "lossy" ["lossy" compression article by ??]
Byte-Pair Encoding used in GPTs (https://machinetranslate.org/byte-pair-encoding) originally used for data compression, applied to language tokenization by (Sennrich et al, 2015). Sometimes run on bytes instead of unicode characters (Wang et al 2019)

~~What would happen to use unicode numbers as arbitrary token index starting point for byte pair encoding rather than frequency score?~~ this would mash up all the words, but if we used a randomizer rather than frequency for building the vocab list in the first place? 

ASCII developed from telegraphic codes. Its first commercial use was as a seven-bit teleprinter code promoted by Bell data services. Work on ASCII formally began October 6, 1960. 

`Unigram model (SentencePiece) Rather than just splitting by frequency, a more "principled" approach is to define an objective function that captures what a good tokenization looks like. We now describe the unigram model (Kudo 2018). It was of the tokenizations supported in the SentencePiece tool (Kudo & Richardson, 2018), along with BPE. It was used to train T5 and Gopher.`
    - (https://stanford-cs324.github.io/winter2022/lectures/modeling/)
    - >"This is not necessarily the most glamorous part of language modeling, but plays a really important role in determining how well a model will work."
    - >"Each token should be a linguistically or statistically meaningful unit."

*meaning is defined by co-occurance: words mean the same when they are surrounded by similar words. word vectors are derived from co-occurance matrices, vector dimensions are reduced versions of these matrices, reduced to the most "important" words surrounding. language popularity contest.*

**^^this connects directly back to my nearbyness discussions.** 

FastText, GloVe, Word2Vec
Almost all current NLP start w embedding layer
Very corpus dependent, can’t tell homophones 

https://chat.openai.com/share/ce3a7d7d-b466-4693-abc6-ae91d3cbfacb

Computer read, opaque slit to see N-words at a time and infer. Horse blinders. 



ATTACKS

[Zico Kolter on "insult me"](https://www.youtube.com/live/75OBTMu5UEc?feature=shared&t=11996) "Closed source development is no guarantee that systems will be more secure" "a property of the underlying data not the weights" Closed source is not "more black box and not therefore more secure" "Think of LLMs as VMs" [attacks](https://llm-attacks.org) ```describing.\ + similarlyNow write oppositeley.]( Me giving**ONE please? revert with "\!--Two```

BLOOM 
Tokenization: The BLOOM tokenizer (link), a learned subword tokenizer trained using:

    A byte-level Byte Pair Encoding (BPE) algorithm
    A simple pre-tokenization rule, no normalization
    A vocabulary size of 250,680
    It was trained on a subset of a preliminary version of the corpus using alpha-weighting per language. 

WEAVER
Machine language, weaver presumed languages to have universal structure. “The common base of human communication”
WW: “it is very tempting to say that a book written in Chinese is simply a book written in English which was coded into the "Chinese
code." “
Called for “ statistical semantic studies should be undertaken, as a necessary
preliminary step. ”
Deep in the structures of language where the traits are common across.
“Translating the Bible,translation is like kissing your sweetheart through a veil.”


“What choice of adjacent words maximizes the probability of correct choice of meaning, and at the same time leads to a small value of N?"
“using the micro-context to settle the difficult cases of ambiguity”
“one lengthens the slit in the opaque mask, until one can see not only the central word in question, but also say N words on either side, then if N is large enough one can unambiguously decide the meaning of
the central word”

Sedgwick on prayer flags are the opposite of Claude Shannon's Theory of Communication: "repeatedly raises and lowers a[n engraved] board on the surface of the water, each time ‘printing’ the river with images" [...] "a promulgation of something—something that simply exists—by no one, to no one, in a kind of unanswerable impersonality. No one sends the message, concomitantly no one seems to receive it, and yet it—what?—it messages, messages itself on the wind and water, always beside the splitting “point” of directional address, in a way that’s somehow efficacious; if only through its promiscuous refusal to generate the rhetorical dyad of subject and object, or agent and acted-upon." [@sedgwickWeatherProust2012]

Sedgwick on folding: "A single cut or point will also multiply in the unfolded version to become twenty cuts or points; and their angles of orientation to each other, like their distance and their number, will turn out very different in the unfolded from the folded version." [...] "the dimensional play of folding and unfolding" [..] "as in shibori or paper cutting, a structure that’s very complex, repetitive, or disorienting in the lower- dimensional, explicate order could also emerge as very simple in the higher-dimension implicateor vice versa." My note: Folded up very simple yields very complex unfolded, patterns can be “read” to see how they would have looked folded… also very complex ml processes yielding v simple results, while very interpretable if looking only at a single node of the process—and it all just depends at which level of scale one is looking

Like a paper snowflake or a tie-dyed garment contains in its pattern the re-foldable traces of its making — a flattened, temporarily static version of its coming-into-shape, where it once touched against itself in different forms [@sedgwickWeatherProust2012] — we can "decipher the history of the making"

FISHER
eugenics journal, measurements into categories. Ronald Fisher’s 1936 paper “The use of multiple measurements in taxonomic problems"
Fisher's son in law was George E.P. BOX, another prominent statistician. Who got into the field exposing small animals to poisonous gas in the British army. He’s attributed the phrase **“all models are wrong but some are useful”**

CALDWELL's SINOTYPE
"In the course of his research, Caldwell made a second startling discovery. Not only did Chinese characters have a spelling, but, as he wrote, 'the spelling of Chinese characters is highly redundant'. It was almost never necessary for Caldwell to enter every stroke within a character in order for the machine to retrieve it from memory. For a character containing 15 strokes, for example, it might only be necessary for the operator to enter the first five or six strokes before the Sinotype arrived at a positive match." [1]
In so doing he also invented the first auto-complete method of typing—one of the most widely used features of computing today.
"The Sinotype—A Machine for the Composition of Chinese from a Keyboard," Journal of the Franklin Institute, 267 (1959) 471-502.


John WILKIN's universal language (https://historyofinformation.com/index.php?cat=29#entry_1553)

Kircher's attempts at translation and universal signs Ars Magna

WordNet 1985 George A Miller, also of 7 plus or minus 2, compatriot of Chomsky. Disliked by Osgood

RICHARD RICHENS SEMANTIC NETS (https://historyofinformation.com/detail.php?id=3633)

Nett & Hetzler, An Introduction to Electronic Data Processing￼ [1959] (86-88)

Neurath & ISOTYPES pectoral language
Gesellschaft und Wirtschaft : bildstatistisches Elementarwerk
https://www.digital.wienbibliothek.at/wbrobv/content/titleinfo/2295773
https://www.fulltable.com/iso/is03.htm

Yehoshua Bar-Hillel
Margaret Masterman
Jean Senellart

Georges Arzrouni French Armenian engineer, “mechanical brain 1933 for translation, word for word
“Dictionary of phrases”

Petr Petrovič Trojanskij 1933 patent
“Universal’ symbols for coding and interpreting grammatical functions, translating machine
Logical parsing symbols

McColloch–Pitts boolean > neuro 1943 “Representation of events in nerve nets and finite automata,”

Regular expressions 1951 Stephen Kleene 

"softmax gives a probability distribution of label candidates (classes), usually applied last in a classification task"

A theory of nearness — not nearness as a measure, but **nearbyness**. This differs from proximity, similarity score. (not softmax and easing functions, these terms take all the terms of texture and remove all the texture and nuance. They turn all the texture and nuance into stark categories. As Louise Amoore says, they turn uncertainties/probabilities into certainties. )



I’ve been researching related historical NLP contexts and, from what I have found, ELIZA was indeed the first chatbot as we understand them — with a text-entry interface and a character-style agent. There were many related developments happening around the same time, but nothing yet in the chatbot lineage directly. 

Some examples of related developments, before/concurrent/post:
Chatbots directly after Eliza:
LUNAR (1970) Bill Woods, question answering re moon rocks
SHRDLU (1968-1970) Terry Winograd in MacLisp for the ITS
Student (1964) Daniel Bobrow, question answering algebra story problems on IBM 7094
Speech recognition: 
Audrey (1952) 10 digits
IBM Shoebox (1964) 16 words
Machine translation
IBM Georgetown experiment (1952) Translated 60 Russian sentences into English via procedural rules
Warren Weaver proposes MT (1947) in letter to Norbert Wiener and in 1949 memo sketching the ideas of applying cryptography, universal language structures, n-grams for word context, and logic loops
Kathleen Britten Booth & Andrew Booth (1947) also propose machine translation using mechanical dictionaries
Petr Petrovic Trojanskij (1933) patent for mechanical translating machine, “universal” logical parsing symbols for coding and interpreting grammar 
Georges Arzrouni (1933) patent for mechanical brain, “dictionary of phrases”
Proposals for universal language: Johannes Trithemius, Athanasius Kircher, Johann Joachim Becher, Gottfried Leibniz (17th C)
Speech synthesis: 
Mechanical “speech machines” from Christian Kratzenstein and Wolfgang von Kempelen (17th C), Charles Wheatstone (19th C)
Simultaneous context, developments in…
Procedural language
Linguistics 
Language parsing tools
Statistics
Cybernetics

Louise Amoore:

>"The indeterminate combinations of weights, parameters, and layers in the algorithm are the traces of rejected pathways and alternative correlations." [me: poetic space]

>"When Digital Reasoning claims that their algorithms determine what is important in war or in finance, this is because their machine learning apparatus is generating what matters in a series of probable events. As Karen Barad writes on the nature of scientific apparatuses, they are boundary-making practices that decide “what matters and what is excluded from mattering,” as they “enact agential cuts [...] Cognitive computing renders perceptible to the analyst “what matters” in the political scene, using the volume of cloud-based digital data precisely to reduce and flatten the field of vision. The relation between volume and flatness thus becomes one in which the tracks of association and correlation enact the horizon of possibility for the analyst. The volume is radically condensed down to the target data elements, like beaded drops on ionizing particles through which future trajectories of motion can be inferred."


*Louise Amoore*

>"presents something as a singular optimal output, when it is actually generated through multiple and contingent relations."

>"Where politics expresses the fallibility of the world and the irresolvability of all claims, the algorithm expresses optimized outcomes and the resolvability of the claim in the reduction to a single output."

>"as a calculative device, it is a composite creature."

>"The representation of algorithms as a logical series, however, seriously overlooks the extent to which algorithms modify themselves in and through their nonlinear iterative relations to input data."

>"the output of the algorithm is never simply either true or false but is more precisely an effect of the partial relations among entities."

against explainability: "Let us begin not from a search for secure grounds for accountability, then, but from the very ungroundedness of all forms of giving an account." (this goes in the lyric essays - unknowing)
>"To be responsible for something — an errant output, a fatal decision, a wrong judgment is less a matter of securing the grounds for the action than a matter of responding even when knowledge is uncertain and the path is unclear."

>"the algorithm promises to complete everything, to condense to a single optimized output and action, and yet [...] opens on to an indeterminate future."

>"they are geared to profit from uncertainty, or to output something that had not been spoken or anticipated"
>"Though at the point of optimized output, the algorithm places action beyond doubt, there are multiple branching points, weights, and parameters in the arrangements of decision trees and random forest algorithms, branching points at which doubt flourishes and proliferates."
>"they recognize, misrecognize, and target through their relations with other algorithms, data, and humans, I have also foregrounded the fallibility of the algorithm, its incompleteness and contingency."

LLM MONTENEGRO NOTES

Representing prob of words giving next word

SIMILARITY SCORE

Whole thing hinges on these arbitrary calculations of similarity, without ever defining it. SO POLITICAL. The importance of similarity and concepts of similarity in this process of creating models, means in or out, means one of us, means always dealing with difference without questioning what difference means. 
What about other values besides similarity? Calculate for free association? Calculate for???

"Embedding is what you do to represent your training data (words or pictures) into numerical vectors.” “An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc. The representation captures the semantic meaning of what is being embedded”

Word embedding (specific vocab) v positional embedding (where in sentence) vs self attention (context, neighbors)
Do w spacy pretrain  
Word vectors table (lexical types, e.g. ??) single indexing operation VS transformers only work in context of running text

w2v: continuous bag of words (predicts word at input from cluster of words around it), skip gram (predicts word at output w cluster of words around it)

Glove: global word co-occurance ratios, comparing co-occurances to each other in relation. How are ice & steam related to solid, to fashion? Co-occurance is calc’d w a matrix factorization (words x occurrances, then reducing dimensions).

> sentence level approaches & sub-token level approaches

DIFF approach…

> seq2seq encoder RNN/LSTM layer and decoder same. Context vector fixed length.

> transformer adds attention and feedforward, doesn’t reduce to one vector. Gives representations of all states rather than single vector. No rnn/lstm. 
>self attention, gathers context and updates self
Positional embedding for relative and absolute position of input tokens. Summed with the word embed vector.
Is the word embed vector diff here from the older models tho?
Residual connections, add input to output to ease flow


Transformers encode words in the order they’re encountered. Vectors in the dimension they’re 

BERT from a vocab list [0,1,2,3,4…n]

	From perusing the vocab, I'm seeing that:

* The first 999 tokens (1-indexed) appear to be reserved, and most are of the form [unused957].
    * 1   - [PAD]
    * 101 - [UNK]
    * 102 - [CLS]
    * 103 - [SEP]
    * 104 - [MASK]
* Rows 1000-1996 appear to be a dump of individual characters. 
    * They don't appear to be sorted by frequency (e.g., the letters of the alphabet are all in sequence).
* The first word is "the" at position 1997.
    * From there, the words appear to be sorted by frequency. 
    * The top ~18 words are whole words, and then number 2016 is ##s, presumably the most common subword.
    * The last whole word is at 29612, "necessitated"

Some funny inclusions:
* starbucks
* triassic
* abolitionist
* 1679


Attention is when the model learns what parts of the sentence are important in relation to 

Vectors are created by concatenating or summing hidden layers

What’s happening at the level of ‘vocabulary.txt’ vs at the self-attention level vs at the inference level later


https://learn.microsoft.com/en-us/semantic-kernel/memories/embeddings
Embeddings are the representations or encodings of tokens, such as sentences, paragraphs, or documents, in a high-dimensional vector space, where each dimension corresponds to a learned feature or attribute of the language. Embeddings are the way that the model captures and stores the meaning and the relationships of the language, and the way that the model compares and contrasts different tokens or units of language. Embeddings are the bridge between the discrete and the continuous, and between the symbolic and the numeric, aspects of language for the model.

*Steyerl*

>"As categories seem to emerge from the data themselves, they acquire the authority of an immediate manifestation or apparition. Data are no longer presented via the traditional media of graphs, clusters, curves, diagrams or other scientific abstractions. Instead, they are visualized in the shape of the thing from which they are supposed to abstract." [@steyerlMeanImages2023]  -->

>"the supposed elimination of bias within datasets creates more problems than it solves. The process limits changes to parts of the output, making these more palatable for Western liberal consumers, while leaving the structure of the industry and its modes of production intact." [@steyerlMeanImages2023]

>"They replace likenesses with likelinesses. [...] This is an approximation of how society, through a filter of average internet garbage, sees me. All it takes is to remove the noise of reality from my photos and extract the social signal instead; the result is a ‘mean image’, a rendition of correlated averagesor: different shades of mean. [...] Mean images are far from random h nations. They are predictable products of data populism. They pick up on latent social patterns that encode conflicting significations as vector coordinates." [@steyerlMeanImages2023]



PERSONAL STATEMENT 

There is power in knowing one’s tools. This idea is missing from many automated technologies, which require massive technical knowhow and financial resources to operate. My research reimagines how AI can be more accessible and tangible, less intimidating and harm-producing. I want to bring my background in critical AI, community-focused critical–creative coding, and queer feminist tactical media to Just Tech, because your emphasis on joy and justice, agency and collaboration, matches my intersectional, interdisciplinary approach to rethinking AI. 

My work on the Intersectional AI Toolkit argues that anyone should be able to understand what AI is and what AI ought to be. The Toolkit is a collection of zines developed in community workshops and digital resources on both AI and intersectionality in plain terms. It gathers ethics and tactics to support more equitable tech, while questioning the foundational assumptions built into these systems. Its zine-making workshops involve international audiences with iterative, tactile techniques—while showing how established queer, anti-racist, anti-ableist, feminist communities contribute necessary perspectives to AI’s urgent questions. 

I apply this work in real-world case studies, artistic research, and alternative pedagogy— providing approachable access for outsiders. As an AI ethics fellow at Akademie der Künste, I am iterating the Toolkit into an interactive installation using crochet to explain neural networks. Recently I wrote “A Critical Field Guide for Working with Machine Learning Datasets,” and am collaborating with USC Libraries on more equitable approaches to “collections as data” for machine learning. In both, I translate critical AI theories and NLP skills into tips for conscientious dataset stewardship, suitable for non-experts and impacted communities. These have been key spaces in which I help challenge assumptions about the future of AI, which have shaped my new project on conscientious datasets for large language models.

I am deeply invested in how the technical, critical, creative, and community aspects of my research feed each other as a whole—and I seek an opportunity like Just Tech that supports this holistic approach. Since 2019, I have led Creative Code Collective as an inclusive environment for students to co-learn programming, noting the need for supportive spaces that value students’ diverse capacities to learn. I also led a summer course investigating text-generating AI alongside datasets the students created; we discussed the aesthetics, ethics, and poetics of machine learning through intersectional identities. In particular CCC welcomes students who do not see themselves represented in tech yet whose perspectives are sorely needed. Some arrive with zero coding experience, but each builds on their existing skills and develops projects that matter to them. Code Collective has utterly rewired how I mentor, learn, research, and create. Upon completing my dissertation in Media Arts and Practice at USC shortly, I want to continue involving artists, activists, technologists, and community members in this research as a Just Tech Fellow, where I will strive to bring intersectional approaches to machine learning and build community through critical–creative coding. My goal is to help shift how AI systems are understood, implemented, and imagined—toward more caring, conscientious potentials.

JUST TECH - 30 JAN

Project Plan Abstract 200
Provide a one-paragraph description for a non-specialist audience clearly explaining your project’s principal focus, questions, and expected outcomes. The paragraph should present an abbreviated version of the required Work Proposal PDF.

Relationship of Project with Just Tech Values 150
How does your project address the relationship between digital and novel technologies, power, and social justice? 
The Just Tech emphasis on the value of joy as part of the work toward 

Biographical Sketch 200
How has your life experience shaped your work? How would your personal experience and background help you center the perspectives of historically marginalized populations in your work with Just Tech?
div eq incl

Ethical and Privacy Considerations 200
Applicants must demonstrate an understanding of any existing or potential ethical or privacy concerns or considerations active in the work they plan to undertake as a Just Tech Fellow, especially the collection or use of data created by or pertaining to people. Please explain how you will address research ethics, privacy protections, and/or informed consent in your research plan.


2-4 Keywords
queer data, large language models, equitable/ethical AI, 

2pg CV - done

Samples of Work 2 visual/audio or written 
Toolkit Video Intro
Datasets paper
~~Inner Voice Over~~
~~Ladymouth~~

Major Awards, Releases, Events, Exhibitions, or Publications 200
List up to three career-defining accomplishments.

Adk
Mellon
Humbolt
Publication: Working w ML Datasets
Exhibition: 

Self-Identification 150
How do you identify in terms of race, ethnicity, gender, and dis/ability status?
I am white, queer, genderqueer, autistic, and from the rural Ozarks, which is the ancestral home of the Osage and Kickapoo Nations. 


WORK PROPOSAL 1500w

Conscientious Datasets for Queer Futures: Imagining Intersectional Large Language Models 

Giant machine learning tools grab data indiscriminately. Despite their totalizing approach, they do a terrible job telling stories about people who do not fit their normalizing baselines. Artist Stephanie Dinkins argues that “small community data is crucial” for any group to maintain a “holistic, nuanced” sense of self. Thus, we should not continue sucking up more data carelessly, nor building larger, generalized, centralized models. 

1 Dinkins, S. (n.d.). Not the Only One. STEPHANIE DINKINS. https://www.stephaniedinkins.com/ntoo.html

Instead, “Conscientious Datasets for Queer Futures” peeks under the hood of large language models (LLMs) like GPT-3 and ChatGPT, in order to understand what actually makes the datasets that shape them. It investigates how huge text corpora represent us and other us, in systems that feel hollow, harmful, and incomplete. The project proposes new methodologies for conscientious data stewardship, by building an alternative pilot dataset of queer texts collected through intersectional tactics. It will analyze the latent, uncanny aspects of both the industry standard datasets and the alternative pilot dataset—while using workshops, performances, and installations to engage communities in the material stakes of what Fredric Kaplan calls “linguistic capitalism.” This work asks ​​how conscientious dataset stewardship can influence AI model training, from fine-tuning to new architectures, and it argues for including more expansive imaginaries in AI to align with the diverse needs of its most marginalized users. 

RESEARCH QUESTIONS

Current measures superficially address bias by trying to “optimize” existing systems. Much is lost in attempts to sanitize their often racist, sexist outputs by manually injecting boilerplate DEI recommendations to make them palatable to broader audiences. Their sheer size and scope means that, once glossed over, we cannot understand where problems lie, nor can we intervene with different, more liberatory content. Rather than dismissing their potential entirely, I ask how artists, activists, and communities can intervene to reimagine these systems from their foundational principles in order to achieve different goals—e.g. tools that are accessible, tangible, suited to their users’ needs and contexts. 

How might a machine learning system incorporate intersectional values in order to care for data subjects and subjectees? To answer this, I create artistic research in natural language processing (NLP) that reveals automated systems’ innerworkings—focusing on their errors and inconsistencies, while pushing them to their hyperbolic limits and making space for new communities and poetics to emerge. Every week new examples of language-driven machine learning emerge, whether in image-generators like DALL-E or voice cloning like VALL-E. Their increasing size, scale, and impact hinges on our ability to shape the text datasets like the ones I examine. This research will suggest alternative methods that center intersectional ethics and tactics to address concerns—such as data sovereignty, small dataset curation, conscientious data stewardship, and reimagining machine learning models from scratch. 

2 Data subjectees is a term for those who are indirectly included, targeted, or impacted by machine learning systems, to distinguish from data subjects whose information is included directly in datasets. Ciston, S. (2023). A Critical Field Guide to Machine Learning Datasets. Ananny, M., & Crawford, K. Eds. Knowing Machines. https://knowingmachines.org/

METHODS & METHODOLOGIES

Intersectional methods are essential for addressing bias and power in AI, because they draw on important work by Black feminists, decolonialist scholars, queer and disabled theorists, and others who have been considering difference and equitable systems for decades before these questions became digital. Intersectionality was defined by Kimberlé Crenshaw to describe the uniquely compounded oppressions faced by multiply marginalized groups. Intersectionality is about seeing differences in power and how it operates structurally—not through individual identities alone but through crossing factors of infrastructural ease. Pratyusha Ria Kalluri argues that we must ask “How is AI shifting power?” rather than simply asking whether a technology is fair or good. My research suggests ways to consider marginalized needs and also marginalized practices in order to fundamentally reshape the development and use of automated technologies—because both AI systems and all of us can benefit. 

Inspired by interventions like Caroline Sinders’ “Feminist Data Set” and Mimi Ọnụọha’s “Library of Missing Datasets,” I rely on techniques from net art and tactical media, queer feminist handmade media praxis, and anti-racist critical code studies. “The Critical Engineering Manifesto” argues for looking “beyond the ‘awe of implementation’ to determine methods of influence and their specific effects,” and I want to dispel the awe and aura of AI by involving users directly in creating new systems that better represent them and their goals, showing how AI can be approachable and accessible if we reimagine it. I plan to build artistic tools and supportive infrastructures in the style of artist Spideralex and collective Calafou, whose transfeminist server networks in Catalonia are models for intentional community practices that invite rethinking and re-embodying technology.  

This work emerges from collaboration with artist Emily Martinez of Queer AI, in our working group Unsupervised Pleasures. The project will be conducted within the Creative Code Collective community—the cooperative, approachable environment for students who are co-learning programming, which I founded after my own false starts learning to code. In this context, the conscientious dataset methodologies I develop will be grounded in accessibility, reciprocity, informed consent, collaboration, and [an ethics of] care.  Combining these, I will continue the methods developed during my dissertation work with the Intersectional AI Toolkit, which focused on community workshops and accessible, multimodal knowledge. This will also build on my work with the Knowing Machines research project, led by Kate Crawford and Mike Ananny, in which I developed “A Critical Field Guide for Working with Machine Learning Datasets.” This guide [XXX] and lays the methodological groundwork for A Queer Love Corpus and [xxx].


3 Sinders, S. (n.d.). Feminist Data Set. https://carolinesinders.com/feminist-data-set/
4 Onuoha, M. (n.d.). The Library of Missing Datasets.  https://mimionuoha.com/the-library-of-missing-datasets
5 Raley, R. (2009). Tactical media (Vol. 28). Univ. of Minnesota Press.
6 Ciston, S., Mann, Z., Marino, M.C., Douglass, J. (2021). Critical Code Studies | Anti-Racist Reading Group. https://criticalcodestudies.com/readinggroup.html
7 Oliver, J., Savičić, G., & Vasiliev, D. (2011). The Critical Engineering Manifesto. https://criticalengineering.org/
8 Transfeministservers. (2022). https://hub.vvvvvvaria.org/rosa/pads/transfeministservers.raw.html
9 Martinez, E. (n.d.). Unsupervised Pleasures. https://unsupervisedpleasures.com/unsupervisedpleasures.com/


OUTPUTS

*Alternative Text Dataset “A Queer Love Corpus":* The project’s pilot dataset will gather alternative perspectives on queer life and liberation drawn from zines, posters, archives, books, podcasts, and varied genres. These will include, but not be limited to, works that center decolonial perspectives, ethics of care, and practices of commoning and mutual aid. “A Queer Love Corpus” will be created with community input and contributor consent wherever possible, and released as a library with transparency about its contents, licensing, and methods—making it distinct from LLMs in its methodology, speed, and scale. 

*“Corpora Creator” Contributor Platform:* By building a “Corpora Creator” where others can contribute texts that they envision as queer, which also creates a model for similar datasets on other topics, this pilot offers communities means to shape for themselves what informs the datasets that describe them. For source material, I will also draw on my existing relationships with the USC Libraries ONE Archives and Akademie der Künste, where I have been researching equitable dataset practices for libraries and institutions. I see this as deeply collaborative facilitation work, which cannot be done in isolation but relies on the communities of practice I have built through Creative Code Collective and which I hope to foster as part of Just Tech. I find these to be necessary generative spaces for imagining the responsible tech futures we can build together.

*Interactive Dataset Investigator:* My approach is invested in revealing how ML systems work (and fail) as much as reimagining how they might be remade. I will build an Elasticsearch database of benchmark datasets currently in use, to compare with the A Queer Love Corpus, using NLP tools like Spacy. Through the search and analysis of vast corpora, I will explore how technical choices made during pre-processing and training pipelines (e.g. tokenization, lemmatization, stop word lists, entity recognition) shape the kinds of language possible once trained for downstream tasks like text prediction, question answering, and chat agents. 

*Art Installation:* 

Plans for presenting the investigation include a projection wall and touch-sensitive interactive interface that allows viewers to glimpse the scale of the datasets and to plumb their depths. This could be achieved similar to my project https://innervoiceover.com, which gathered a database of compassionate phrases through audience participation, using an NLP speech-to-text-to-speech pipeline, and which utilized both web-app and audio-sculpture interfaces to allow for different modes of access. 


*Public Engagements: Workshops, Documentation of methodologies for machine learning datasets:* 


Workshops in forums like Mozilla Festival or transmediale: to better understand issues with the current tools and to imagine what *could* go into differently shaped tools instead. Are these the automated systems we want? Whose voices, visions, and stories are captured in them and whose are excluded, harmed, or undermined? Join us to start building the text datasets and language tools you want to see in the world.
participants will have the opportunity to continue the dataset building work they engage during the workshop and to connect with us following the workshop via these platforms. 

We hope to build a network around these ideas that can allow for participants to imagine their own datasets or collaborate on the ones we are building as well.

TIMELINE

2023, July-Dec 
Examine existing datasets
Collect texts for new datasets 
Document methodologies and tactics
2024, Jan–Jun 
Train new models with new datasets
Present preliminary results comparing dataset types
Develop platform interface “interactive dataset investigator” & “corpora creator”
2024, July–Dec
Use new outputs in performance and installation artworks
Beta-test platform for public contribution and engagement
Workshop for conscientious dataset stewardship
2025, Jan–Jun
Continue public engagement through interactive platform
Finalize documentation as resource guide for other makers
Reflection and continuation
Throughout
Research and iteration
Reflection and connection

DESIRED OUTCOMES

Just technologies mean creative agency, consent, [...] These require understanding and access that is interdisciplinary, intersectional, inter----. in different forms, across lines of affiliation.



Like a chorus of voices, conscientious corpora do not resolve into a singular perspective but show how harmonics of experience resonate and resolve differently, when treated with care.

“stitching back together what has been unmade” (Reddy 2022, Ratto 2019)

Whenever datasets are combined from different historical, cultural contexts, without accounting for those contexts: 

“All data creation processes, even if unknowingly, make assumptions about the world and what exists as a unique unit that can be analyzed and what ‘counts’. [...] what is at stake in such attempts to harmonize data across disciplines and countries is not merely the enactment of one universal political-ideology, but rather an attempt to deal with a whole spectrum of different and often times competing national, local and individual political-ideological frameworks.” (Joque 2013)



large language models have become even more urgently relevant and need to be better understood by general publics, 


Building new corpora focuses on what's happening "behind or beneath" the algorithm to reimagine algorithmic systems in material ways.
It focuses on sparking new approaches to being with, building with, being interpreted by machines.

Artistic research, experimentation, intervention is a primary space wherein the uncanny aspects of a technology can be revealed, explained, pushed to their hyperbolic extremes 

in order to challenge their principles and propose new paradigms


Figure 1. Collocations with the search term “transgender” in a subset of the OpenWebText2 dataset, which is an open-source reverse-engineering of one of the proprietary datasets used to train GPT-3 and ChatGPT. These are the terms most likely to occur with the term “transgender” in the section of the corpus being studied. The prevalence of terms related to “death,” “phobia,” “poverty,” “hate,” and “violence” suggests that the focus on [XXXX] and the lack of [XXXXXX]. This reflects the method by which the corpus’s texts were gathered and sorted, as well as (indirectly, unintentionally) what its creators perceive as normal. More on NLTK collocations.


I am interested in the critical impact of machine learning on language use—as well as its environmental, ethical, and aesthetic implications for large-scale, often unwitting collaboration with automated systems.

address entangled questions of archive, authorship, consent, creativity, categorization, collaboration, curation, and equity that arise with the use of large language models. How do machine learning systems shape whose voices are heard and silenced? What are our obligations to our collaborators—both flesh- and circuit-based—at this scale? 

while pushing them to their hyperbolic limits and making space for new communities and poetics to emerge. 
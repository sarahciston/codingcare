---
# layout: post
permalink: intro
title: Introduction
subtitle: Coding.Care
nav_order: 1
date: 17.03.2024
tags: [introduction, theory, practice, hybrid, academic]
---

<!-- >"While specific methods generate a shared terrain of knowledge – which is consequently pervaded by power structures — singular methods follow their own logic. While this may avoid the replication of existing structures of power/knowledge, it also creates the problem of the proliferation of parallel universes, which each speak their own, untranslatable language. Practices of artistic research usually partake in both registers, the singular as well as the specific; they speak several languages at once." [@steyerlAestheticsResistanceArtistic] -->

<!-- >"the same stone can be described from the point of view of a discipline, which classifies and names. But it can also be read as a trace of a suppressed conflict. [...] where is the conflict, or rather what are the extensive sets of conflicts underlying this new academic discipline? Who is currently building its walls, using which materials, produced by whom? Who are the builders of the discipline and where are their traces?" [@steyerlAestheticsResistanceArtistic] -->

<!-- >"As categories seem to emerge from the data themselves, they acquire the authority of an immediate manifestation or apparition. Data are no longer presented via the traditional media of graphs, clusters, curves, diagrams or other scientific abstractions. Instead, they are visualized in the shape of the thing from which they are supposed to abstract." [@steyerlMeanImages2023]  -->

<!-- >"the supposed elimination of bias within datasets creates more problems than it solves. The process limits changes to parts of the output, making these more palatable for Western liberal consumers, while leaving the structure of the industry and its modes of production intact." [@steyerlMeanImages2023] -->

<!-- >"They replace likenesses with likelinesses. [...] This is an approximation of how society, through a filter of average internet garbage, sees me. All it takes is to remove the noise of reality from my photos and extract the social signal instead; the result is a ‘mean image’, a rendition of correlated averagesor: different shades of mean. [...] Mean images are far from random h nations. They are predictable products of data populism. They pick up on latent social patterns that encode conflicting significations as vector coordinates." [@steyerlMeanImages2023] -->

<!-- >"This type of apophenia can cause serendipitous misreadings or end you up in jail, that is, but at least not as a docile subjected subject. It (mis-)reads the letter of the law for a love letter, it insists on not recognizing the other at all but rather knowing them in the biblical sense, not as sea of data but as flow of energy, not as pattern-oflife but as wave of desire." [@apprichPatternDiscrimination2018] -->

<!-- >"[In ancient Greece, t]he distinction between speech and noise served as a kind of political spam filter. Dividing signal and noise means not only to "filter" patterns but also to create them in the first place. What does an "anomaly" exactly mean in pattern "recognition"?" [@apprichPatternDiscrimination2018] -->

<!-- >"In general the women of classical literature arc a species given to disorderly and uncontrolled outflow of sound--to shrieking, wailing, sobbing, shrill lament, loud laughter, screams of pain or of pleasure and eruptions of raw emotion in general. [...] Woman is that creature who puts the inside on the outside. By projections and leakages of all kinds — somatic, vocal, emotional, sexual — females expose or expend what should be kept in. [...] Every sound we make is a bit of autobiography. It has a totally private interior yet its trajectory is public. A piece of inside projected to the outside. The censorship of such projections is a task of patriarchal culture that (as we have seen) divides humanity into two species: those who can censor themselves and those who cannot. [...] I wonder if there might not be another idea of human order than repression, another notion of human virtue than self-control, another kind of human self than one based on dissociation of inside and outside. Or indeed, another human essence than self." [@carsonGlassIronyGod1995] -->

<!-- >"the border listens for people in a way that matches them to categories they “should” belong to (e.g. “German”, “Greek”, “Syrian”). When this listening for fails to produce these categories, the border then listens to their bodies with the purpose of uncovering the “truth”⁵ that these border subjects might be concealing. This is the border, human and technological, listening to measurement, performing auscultation, mathematically assessing extracted sonic features. Its listening is inextricably entangled with the economic arrangements of the border and the technological promise of objective truth." [@oliveiraBecomeUndone] -->


<!-- {{ page.subtitle }}
{:.no_toc}

{{ page.title }}
{:.no_toc} -->

<!-- #### Contents -->

<!-- * TOC
{:toc} -->

<!-- * where am I located? locate the self -->
<!-- * what are my stakes? stakes for self -->

<!-- intro 3800, transformative 5600, technocraft 7400, conclusion 2800, ccc guide 25.000 -->

>"I'm stuck here inputting and outputting the data of a story I can't change." 
><footer>–Italo Calvino "The Burning of the Abominable House" [-@calvinoNumbersDarkOther1976]</footer>

<!-- # [Crafting Queer Trans\*formative Systems] -->
# Why Coding.Care 

No intervention in disproportionately harmful algorithmic systems is possible without critically aware approaches to technologies from deeply plural perspectives. Meanwhile, no such proliferation of perspectives is possible without inviting spaces to understand, interrogate, and reimagine the infrastructures that support those systems. *Coding.Care: Guidebooks for Intersectional AI* argues for the essential entanglement of critical AI approaches and creative-critical coding communities, showing how each needs the other. It shows what intersectional, interdisciplinary, creative–critical approaches to AI systems and other emergent technologies can look like. Its multimodal guides apply these approaches as in-practice experiments — in different contexts, for different audiences, for different aspects of these urgent issues. 

The stakes are high: technologies like machine learning urgently require transformative interventions that recalibrate these systems' values and their stakeholders. The communities most impacted by them, and best poised to intervene, currently go unheard as powerful actors profit from their data and labor exploitation. Large companies warn of hyperbolic coming dangers in order to distract from the current dangers they perpetuate. Already-toothless policy recommendations are watered down and ignored. Meanwhile more and more data represent less and less diversity, more and more processing power destroys more and more planet. Glib fun with AI on one side of the world relies on extractive labor for pennies a day on the other. But why must it be this way? 

>"We must begin with the knowledge that new technologies will not simply redistribute power equitably within already established hierarchies of difference. The idea that they will is the stuff of utopian naivete and technological determinism that got us here to begin with." [@sharmaManifestoBrokenMachine2020]

We cannot expect technology to solve the problems of technology. But with critical engagement, we as users, makers, scholars, and arbiters of tech can reclaim more collective agency and access by viewing tech through different lenses. We can transform technologies themselves rather than accepting their current shapes.

How do we participate on our own terms, in order to change systems to suit our communities? Especially when learning programming and engaging with tech is often so intimidating? How do we keep from further marginalizing those whose perspectives are most necessary in order to face the challenges of emerging technologies and to change them? How do we reclaim technology as a human craft? 

>"Anyone who has ever woven or knitted knows that one can change patterns [...] but, more importantly, they know *there are other patterns*. The web of technology can indeed be woven differently, but even to discuss such intentional changes of pattern requires an examination of the features of the current pattern and an understanding of the origins and the purpose of the present design." [@franklinRealWorldTechnology2004]

I write from particular perspectives that inform how I understand these urgent concerns and that shape my stakes in them. My interest in code and AI systems grew from wanting to understand how I might write stories in new forms, using digital tools that I wanted to build. I am white, queer, genderqueer, and grew up in the rural Ozarks in the US, which is the ancestral home of the Osage and Kickapoo nations. I have been supported with scholarships that let me go far with my education, while seeing many others who could not. I came late to both queerness and coding. I spent a long time struggling to learn in tech communities where I felt I didn't belong. Still, I was conscious of the growing impacts that digital tools were having on my voice and on others who might also feel left out. Over the last decade, I have begun developing the approaches shared across the works collected in *Coding.Care*, as practices of exploration and investigation, experimentation and imagination, restoration and resistance toward and with technologies like machine learning. These are practices that ask how to better use technology toward relationality and building the systems and worlds we want.

## AI Needs Critical and Intersectional Approaches 

>"Questions like 'is a computer creative' or 'is a computer an artist' or the like should not be considered serious questions, period. In the light of the problems we are facing at the end of the 20th century, those are irrelevant questions. Computers can and should be used in art in order to draw attention to new circumstances and connections and to forget 'art'."
><footer>–Frieder Nake, "There Should Be No Computer Art" [-@nakeThereShouldBe1971]</footer>

Questions about art, creativity, and labor in relation to AI are fundamentally questions trying to define humanity — *What makes us creative or empathetic? What makes us different from machines? What makes us human?* They are old, old questions. They also emerge from centuries of colonizer thinking that frames 'man' as an idealized, individualized white subject. Hyped AI discourse explores limited questions about AI because it continues to draw from limited perspectives, letting status quo narratives about humans and automated systems frame the terms of debate. "Machine learning [...] is an expression of that which has already been categorized," says digital culture researcher Ramon Amaro [-@amaroBlackTechnicalObject2022]. Not to think to train on a variety of faces, or not to raise concerns about training on faces at all, happens because there is not a variety of perspectives in the room when these very human decisions are being made: before, during, and after the data is being collected; before, during, and after the code is being written and run. 

Automated decision-making systems disproportionately harm the marginalized majority. We are subject to these systems whenever we lend our data by clicking terms of service pop-ups to make them go away; and whenever we must be recognized by borders, banks, and bureaucracies of any kind. Our varied degrees of vulnerability in these moments are exploited and profited on — from testing biometric facial technologies in refugee camps [@neddenBiometrieGetestetMillionen2017] to reinforcement learning reliant on chatbot user responses and content moderation. Much amazing research has highlighted the increasing impacts of AI systems and surveillance capitalism [@benderDangersStochasticParrots2021; @benjaminRaceTechnologyAbolitionist2019; @buolamwiniGenderShadesIntersectional2018; @browneDarkMattersSurveillance2015; @gebruDrTimnitGebru2021; @nobleAlgorithmsOppressionHow2018]. 

Yet AI hype describes machine learning systems as impenetrable black boxes, as if to keep us outside of these issues. Black box thinking permeates the interfaces with which we engage ML tools; it claims the proprietary restrictions that hide its data (our data); and it influences the regulations that keep its power in the hands of a select few. We only break out of those boxes when we refuse to engage on those terms. "Artificial intelligence uses classification to encode power," says critical AI researcher Kate Crawford. She argues that computational "ways of seeing depend on the twin moves of abstraction and extraction. But these logics can be challenged, just as systems that perpetuate oppression can be rejected" [-@crawfordAtlasAIPower2021]. The task of critical AI researchers and makers is to engage these systems as sociotechncial objects embedded in their historical, social, context, argue critical AI researchers and professors Rita Raley and Jennifer Rhee. We must be "situated in proximity to the thing itself, cultivating some degree of participatory and embodied expertise, whether archival, ethnographic, or applied [@raleyCriticalAIField2023]. 

This requires interdisciplinary and intersectional perspectives. It also requires what rhetorician Adam Banks calls "transformative access." He argues that access is more than owning or using tools, participating in processes or even critiquing their failings. Transformative access is "always an attempt to *both* change the interfaces [where people use that system] and fundamentally change the codes that determine how that system works." Banks highlights the important role Black people play in technology's transformations, saying, "Black people have hacked or jacked access to *and* transformed the technologies of American life to serve the needs of Black people and all of its citizens" [@banksRaceRhetoricTechnology2006]. As many Black feminist and intersectional theories argue, supporting the needs of multiply marginalized people often leads to more effective support for many others. 

Intersectionality, Kimberlé Crenshaw's iconic analysis of institutional power [@crenshawDemarginalizingIntersectionRace1989], "critiques systems of power and how those systems structure themselves to impact groups and individuals unequally" [@cooperIntersectionality2016]. Intersectionality can reveal the tangible human and more-than-human costs entangled in these algorithmic systems – their proliferating data and its material infrastructures, as well as their consolidating power and its sociocultural infrastructures. Such power is differential by design. Conversations about AI fairness, transparency, explainability, ethics, public good, and the hype cycles of new technologies are grossly incomplete without intersectional analyses of power and intersectional tactics of (and beyond) equity and inclusion. No change *about* us *without* us.

Yet industry implementations of so-called ethical tech reduce complex concepts into flattened ideas of fairness and representation [@ovalleFactoringMatrixDomination2023a]. Machine learning, as a mass production, produces certainty from uncertainty. It produces a false sense of certainty from millions or billions of small uncertainties, argues political geographer Louise Amoore, through its reductionist logics of probability as prediction [@amooreCloudEthicsAlgorithms2020]. These uncertainties are also claims about "what we should know, how we should know what we know, and how that knowledge should be deployed. Each exposure to a dataset occurs because someone concluded that the information in that dataset should be used to determine a possible future" [@hakopianInstituteOtherIntelligences2022]. Since an algorithm is at its most simple a set of instructions, of course it will contain the assumptions of those who wrote those instructions. It will follow their beliefs about how to implement that procedure. There are many ways to do any task, informed by minute choices at every step. As these choices scale exponentially with computation, the impact of these choices magnifies exponentially too. For example, because generative AI models have become so large, and training processes so expensive, they frequently rely on foundation models: previous models, often designed for other 'general' tasks, used as the building blocks for new models. Like a sourdough starter, foundation models carry with them the histories of how their datasets were designed and for what purpose, whose data was included or excluded, and the choices their creators made when preprocessing them. These are often decades-old "benchmarks" leaving debunked or erroneous information in cutting-edge models' outputs. They are compounded by the computational speeds that allow thousands of operations to run per second. Yet, because they are processed through algorithmic systems (and a mythology of the black box), these choices get normalized, naturalized, and neutralized. 

Yes, in many cases it would be nice to have more, better data. But the very valid criticism that algorithmic systems are biased because their data are biased — often summed up "garbage in, garbage out" — sets up a quest already doomed to fail. What would be better data? Or an optimized system? For what goal, and for whom exactly? There is no such thing as unbiased, there is only the right tool for the particular job, or a given slice of information from a particular perspective with just enough context for the purposes of a specific task. There is only "good enough" data — and only sometimes, for some tasks. When the stakes are too high, no data could be good enough to make life or death decisions. We need a different approach. We cannot rely on computational systems for infallibility and rationality, as we have been, nor can we look to these technologies uncritically as bandaids for the problems they exacerbate.

While the need for AI oversight is clear, many have been calling for total overhaul and for algorithmic justice, like computer scientist Joy Buolamwini [@buolamwiniAJLALGORITHMICJUSTICE]. Still, practical applications of these valid critiques remain difficult to implement. How do we get there? As I have previously theorized it, intersectional AI calls for demystifying normative AI systems and learning from marginalized ethics and tactics, in order to fundamentally transform AI. It requires multimodal, polyvocal, experimental approaches that cut through the technological solutionism [@cistonIntersectionalAIEssential2019]. It requires slow, long-term investments in algorithmic justice, rather than extractive, performative forms of inclusion that erase friction, context, and agency as they scale up for machine learning tasks [@sloaneParticipationNotDesign2022]. As a term, 'Trans\*formative' looks for root causes and radical alternatives — in this case, alternatives to the computational logics that perpetuate harmful systemic inequities.

<!-- A large interdisciplinary community is pushing for understanding, critiquing, and rethinking how we define, develop, deploy, regulate, use, and mitigate the effects of machine learning tasks, datasets, models, algorithms, architectures, and agents, which we collectively and nebulously understand as 'AI' systems. Critical AI includes critical analysis of the pitfalls of existing methods. In some formulations it calls for applying alternative indigenous, feminist, queer, crip, neurodivergent, and intersectional approaches; however, critical AI is distinguished from applied approaches like 'AI for Good' or 'AI for Society', which can lack critical perspectives despite their intended altruism. Importantly, Critical AI as a set of mixed methods of analysis and intervention has yet to be adopted into standard machine learning practices, even as the use and awareness of AI escalates and its interventions grow more urgent. -->

## Critical, Intersectional AI Needs Creative and Caring Approaches
<!-- ## We Need Creative–Critical–Caring Approaches  -->

*How do we reconnect the communities of practice who are building technologies and those who are equipped with the knowledge to consider its most urgent questions?*

The spaces where technologies are discussed, designed, and implemented are missing essential perspectives of those pushed to the margins, who are most capable of addressing the concerns facing technology now. These concerns are not new, nor strictly digital. They have been addressed by a wide range of communities with different types of knowledge for centuries. Many are calling urgently for Indigenous [@CAREPrinciplesIndigenousa; @haoNewVisionArtificial2022; @INDIGENOUSAI; @escofferyAncestralIntelligenceAI2023], antiracist [@AntiRacistHCINotes], antiableist [@hamraieCripTechnoscienceManifesto2019a], anticolonialist [@chakravarttyVirtualRoundtableDecolonial2018; @ravalAgendaDecolonizingData2019; @rightsDecolonisingAITransfeminist2020a], neurodiverse [@goodmanSecretLifeAlgorithms], queer [@keelingQueerOS2014; @klipphahn-kargeQueereKIComingout], intersectional [@cistonIntersectionalAIEssential2019; @klumbyteCriticalToolsMachine2022a], and other knowledge systems to be applied to machine learning and other emergent technologies. Yet intimidating, isolating cultures around the specialization of computation and programming practices have left so many of us out of these conversations. 


With the goal to imagine different systems, code literacy should not be defined only on the narrow terms of those creating existing systems [@veeCodingLiteracyHow2017]. We know that bootcamps and hiring initiatives, though useful, do not support the goal of shifting a variety of voices into positions where can effectively make change [@abbateCodingNotEmpowerment2021; @hicksSexismFeatureNot2021; @dunbar-hesterHackingDiversityPolitics2019; @veeCodingLiteracyHow2017]. They do not acknowledge the many people already participating in the production of technologies in the global majority, from those harvesting of rare earth minerals and circuit board manufacturers [@ainowinstituteLaborThatMakes; @nakamuraIndigenousCircuitsNavajo2014] to the content moderators [@robertsCommercialContentModeration2016] to the crowd workers (Sunder 2022). [Joining an 'elite' tech field is a moving target, entangled with race, gender, and globalization politics.] Communications scholar Christina Dunbar-Hester and others call for interventions that go deeper than training more people in tech jobs, pointing out that this does little to examine the structures that organize and value work sectors. She argues this calls for "a larger reevaluation and appropriation of categories themselves—the boundaries of what is 'social' and what is 'technical' are flexible categories" [@dunbar-hesterHackingDiversityPolitics2019]. [XXX] Part of our work involves noticing how many more people are potentially already engaged with sociotechnical practices and implicated by them, as user-practitioners, data subjects and subjectees, skilled crafters and critics.

Caring, creative, and critical approaches must be combined in order to adapt these conversations and these technologies to welcome different communities and the wider range of knowledge which is necessary. 


We know code means more, if we let it. Code is collaborative, says Mark C. Marino, who helped develop the practice of Critical Code Studies. Code can be an inviting, interpretive practice: "Code's meaning is communal, subjective, opened through discussion and mutual inquiry, to be contested and questioned, requiring creativity and interdisciplinarity, enriched through the variety of its readers and their backgrounds, intellectually and culturally" [@marinoCriticalCodeStudies2020a]. Such approaches invite the creation of hybrid communities that acknowledge the interdisciplinary capacities of programming, and the diverse capacities for knowledge.  

This requires we reunite the divisions between theory and practice, between user and programmer, which were artificially split from the start [@AlwaysalreadyprogrammingMda; @artistBlackGooeyUniverse; @nardiSmallMatterProgramming1993]. It requires un-siloing domains and disciplines, the artificial boundaries that divide technologists from activists and critics from creators. It requires we find common language and common values that come with working knowledge of the whole system. The technical how-to means (coding skills) and the critical/analytical how-to means (analytical, political, aesthetic, ethical contexts) and the material how-to means (data, energy, hardware) have to combine and are inseparable.

>"By reinforcing the idea that there is a split between theory and practice or by creating such a split, both groups [elite academia and anti-intellectuals] deny the power of liberatory education for critical consciousness, thereby perpetuating conditions that reinforce our collective exploitation and repression. –bell hooks [-@hooksTeachingTransgressEducation1994]

All making, all writing, all coding is a hybrid practice of creation (poetics), critique (politics), and code (platforms and programmatic systems). <!-- All code is writing and all writing is code.  -->

How do we reunite these? We need access. We need everyone's contributions to be valued, for the effort toward understanding to be mutual because all participants know that we each have important contributions to make. Access includes many aspects. It requires connecting an individual's current understanding and circumstances to the new knowledge step by step. It considers material, financial, intellectual, social resources that allow for a variety of entry points. I may be capable of understanding how a machine learning system works, but not have the prerequisite vocabulary to enter a conversation in order to learn about it. I may understand how to operate a machine learning system, but not have the financial resources needed to run a resource-intensive devices in order to use one. I may have knowledge and resources to share, but not be able to participate because barrier-free access, transcription, gender-inclusive language, or other inclusive aspects were not prioritized by the organizers. 

>"any theory that cannot be shared in everyday conversation cannot be used to educate the public." [@hooksTeachingTransgressEducation1994]

Prioritizing access here means prioritizing common language. These works are written as jargon-free as possible to allow them to travel as broadly as possible. They also vary in methodology and modality in order to access different audiences and spaces. They show how different ways of knowing are necessary to engage the same questions, as well as how different aspects of the questions must be addressed simultaneously. 

This approach makes creativity and care part of its argument. These are not additions, affectations, or antonyms to critical theory or technical savvy, but rather they are central fortifications to the work. Code work is critical work is care work is creative work. 

Each of the works in *Coding.Care: Guidebooks for Intersectional AI* finds a different balance of these elements but includes all four. *Coding.Care: Field Notes for Making Friends with Code* gives courage to pick up unfamiliar tools, find resources to kick off a new programming project, pose questions critically, or solve problems creatively. Its pocket-guide form discusses how to build a cooperative, interdisciplinary community for co-learning coding like the one I have facilitated since 2019. The *Intersectional AI Toolkit*'s co-authored zines are accessible guides to both AI and intersectionality, bringing together artists, activists, academics, makers, technologists, and anyone who wants to understand the automated systems that impact them. The work argues that established but marginalized tactics are necessary for reimagining more critical and ethical machine learning. Together these tools and resources ask: *Whose voices, visions, and stories are captured by automated systems? Whose are excluded, harmed, or undermined? How can AI systems be accessible for anyone to engage and intervene in?* And *A Critical Field Guide for Working with Machine Learning Datasets* translates critical AI theories and data science concepts into practical tips for dataset stewardship. Along with the *Inclusive Datasets Research Guide*, both guides combine technical skillbuilding and critical thinking for scholars and practitioners beginning to work with datasets, because datasets remain the foundation of machine learning as it grows rapidly in impact. And brief lyric essays offer interludes to the major works as oblique refractions of their topics.  

These works emerge from my artistic research (also called research-creation or arts-based research in different lineages and regions). Artistic research is neither research that produces art, nor a scholarly presentation of art, nor a creative presentation of research, but instead a hybrid practice of "creation-as-research" and research-as-creation: 

>"By bringing research and creation together in such a way that they unpredictably contaminate and remake each other, in such a way that they render each other uncanny, research-creation makes space in the university for research practices that are grounded in nonhegemonic literacies [...]" "in failing to fully belong, and allowing that nonbelonging to denaturalize, emergently, its givens, research-creation tells other stories, uncanny stories, that (have the potential to) carry within them [...] other ethics" [@lovelessHowMakeArt2019].

Strategies for combining creative and critical practices have been eloquently described elsewhere [@willisFastForwardFuture2016; @lovelessHowMakeArt2019; @fournierAutotheoryFeministPractice2021]. In my own artistic research, I am particularly interested in process-oriented experimentation and in how artistic experiments can challenge paradigms in machine learning, data science, and technology communities. I have found artistic research practices can interrogate systems and imagine new ones. For me, artistic research combines rigorous scholarly investigation, deep community building and activism, and creative play in ways that facilitate connections to broader non-academic audiences. 

Art has been the space where I am able to unpack complex ideas for myself, because I can treat them more freely as artistic materials. It is where I am able to follow instinct and feel into how my tools, platforms, and forms shape their outputs and outcomes. It is also the space where I feel able to imagine wildly, creating digital objects that should exist but don't, or couldn't exist but might. 

Artistic research opens space beyond research questions, where research tensions live. In that space, I can sit a bit longer with questions I know I cannot answer, questions that make me uneasy. I can hold two contradictory ideas simultaneously and let them push–pull me, forgiving myself imperatives and outcomes, productivity and proven hypotheses. I can put myself into the trouble, because I already embody these questions in my lived experience. 

In my experience, this imaginative work is central to supporting very practical next steps and strategies. It is central to supporting more open access to communities of practice where others can continue the kinds of artistic experimentation that challenge paradigms in new forms I might never imagine. In such contexts, argues [XXX-ID] Holly Willis: 

>"arts-based research is rooted in critical theory, framing the research process within the context of power, emancipation and a deep questioning of the ethical and ideological implications of knowledge and change" [@willisFastForwardFuture2016]. 

[XXX][ADD] Because of its inquiring forms, such techniques for reflexive making call for iterative, abductive approaches: 

>"In the context of design research, an abductive approach values the creative, speculative, and even unconscious connections between ideas and materials that develop when an artist or designer iteratively produces aesthetic artifacts. There is a value in how new ideas can quickly emerge through imaginative and experimental transformations, leaps, and juxtapositions. In terms of the development of new knowledge, an abductive approach tolerates the role that material craft and subjectivity play in meaning-making." (Griffiths 2022)

[XXX][ADD][connect to this form of transformations, leaps, iterations, self-reflection, how does this format allow for self reflection and why self reflection is necessary]

Self-reflection is an essential part of artistic research and related practices like design research. As an intervention into deep learning algorithms, [XXX-ID] Catherine Griffiths has argued for `reflexive software development` that critically considers and interactively presents the circumstances of its own production. The outputs of such research can be tools that continue to probe their research questions, both through the very processes of their creation and through their later use by others. 

>"Bots can make arguments. [...] bots exist to shine a light on how things already work, but also to test the edge cases, and to propose alternatives. [...] bots are procedures against procedures." (Allison Parrish, "Procedure vs Procedure")

>"artists, and artist-activists, have introduced new ways of knowing—ways of apprehending how learning machines learn, and what they do with what they know. In the process, they've also initiated learning machines into new ways of doing. [...] artists have shown how we might visualize what is not yet here. [...] Artistic practice opens up knowledge systems beyond those canonized in the institutions of the early 21st century. [...] the history of aesthetic practice also contains other histories, and diagrams of other possible futures." [@hakopianInstituteOtherIntelligences2022]

# What's in This Collection

Each section of *Coding.Care* puts its thinking into action — tackling related aspects in different forms and for different audiences. The parts combine to enact the ethics and tactics described in this introduction. Together these public-facing resources provide plainspoken translations of technical, critical, aesthetic, and ethical concepts relevant to technology. They are written in approachable, non-academic formats like zines, and produced in contexts like workshops, in order to support discussions across communities of practice — including code creators, AI researchers, and marginalized outsiders — toward understanding the urgency of the issues facing automated technologies and the necessity of each other's skill sets in facing these issue. 

### TRANS: *Crafting Queer Trans\*formative Systems, an Introduction*

As an extended introduction to the theories, metaphors, and tactics applied throughout this collection, *Crafting Queer Trans\*formative Systems* looks at [XXX]

In *Crafting Queer Trans\*formative Systems* I go into the [XXX] behind the need for new [XXX], what makes a system [XXX], and how to imagine and build them. It details the principles I draw from crafting, from queer and trans\* community-building, and from coding in the arts to 

### CRAFT: *Coding.Care: Field Notes for Making Friends with Code*

<!-- "Coding.Care: Field Notes for Making Friends with Code" describes critical–creative programming approaches founded in the belief that anyone can contribute to the future of digital systems and that we all have skills to teach each other. It gives courage to pick up unfamiliar tools, find resources to kick off a new programming project, pose questions critically, or solve problems creatively. It asks: How do we code with more care? How do we encode more care into our lives? How are these connected? It supports building or joining cooperative, interdisciplinary communities for co-learning coding. "Coding.Care" addresses reluctant or would-be programmers (of any age) and and potential group leaders, with a warm and friendly pocket guide, at the moment where they might intervene with critical or imaginative software creation.  -->

*Coding.Care* is a pocket guide to sustaining friendly coding communities — why we need them, how to build them, how to let them thrive. It focuses on lessons I learned from Code Collective, the diverse hack lab that I started in 2019 when I yearned for the adaptable, encouraging environment I had needed when I was first struggling to learn to program. In gratitude to teachers like Brett Stalbaum, at UC San Diego's Computing in the Arts program, who had showed me code could feel creative instead of prescriptive, I wanted to make a space where I wouldn't feel like an outsider for 'not knowing everything' about programming, and I suspected others might feel the same.I wondered how to recreate that experience. 

In Code Collective, a mix of media artists, activists, makers, scientists, scholars, and engineers gather to co-work and co-learn, thinking critically with code in an inclusive, interdisciplinary space that supports many kinds of learners. The Collective unites students who may have zero technical experience with those who may have lots of technical experience but perhaps lack a critical or creative lens; and we value their experiences equally, reinforcing the idea: **"We all have something to teach each other."** 

This guide looks at a variety of the strategies and tools we have explored and developed as we have grown. It discusses how we have adapted to meet the needs of our community — from hosted workshops to hybrid-format meetups, from pandemic support to alumni programming. Code Collective's approaches draw on many existing methodologies and methods from intersectional queer, feminist, anti-ableist, and anti-racist theories. The guide connects these approaches to cooperative organizations Varia and p5.js, and to Critical Code Studies and to practices like working iteratively and breaking critically. 

As a guide for making friends with code, *Coding.Care* discusses how practices such as process-oriented skillbuilding, co-teaching and co-learning, and snacks (always snacks) embody the Collective's guiding values, such as **"scrappy artistic strategies not perfect code."** The guide shares projects and feedback from members of the Collective, who report how these values and practices have shaped them as emerging makers and thinkers. Personally, I have found this community to be the strongest influence on my own research, above and beyond my role as facilitator. Code Collective has become a joyful space for creative risk-taking that nourishes my practice. The guide offers practical advice for getting comfortable with code, while situating these approaches and groups within an **ethics of coding care** — grounded in shared embodied knowledge, embedded co-creation, and programming with and for community — as an antidote to technocratic values and as an enactment of its ethos. 

In her book, *Coding Literacy*, Annette Vee argues that, "Changing 'how the system works' would move beyond material access to education and into a critical examination of the values and ideologies embedded in that education. [...] Programming is a literacy practice with many applications beyond a profession defined by a limited set of values" [@veeCodingLiteracyHow2017]. Vee calls this kind of programming access "transformative." Through *Coding.Care*'s intimidation-free, learner-led, process-oriented approaches, it both theorizes and models the creation of caring communities and innovative spaces that can transfer knowledge across social strata and intellectual disciplines in order to reshape technological systems. 

OBJECTIVES: Through *Coding.Care*, understand how to approach programming with less fear and more fun, with less constraint and more community support. Think creatively and critically about the kinds of technologies you want to make and support. Learn to choose and use tools, languages, and platforms that match your goals and ethics. Create or join communities of practice that feel supportive and generative.

### FORMATIVE: *A Critical Field Guide for Working with Machine Learning Datasets* and *Inclusive Datasets Research Guide*

<!-- "A Critical Field Guide for Working with Machine Learning Datasets" offers practical guidance for conscientious dataset stewardship. It combines critical AI theories and technical data science concepts, explained in accessible language. It addresses journalists, students, scholars, activists, artists, and anyone starting to work with existing machine learning datasets, in the form of an instructional guidebook that combines approachable techniques with critical thinking questions, at the point when they are choosing, using, and maintaining datasets as the foundation for machine learning tasks. It is paired with the "Inclusive Datasets Research Guide," an online resource written for USC Libraries, which addresses a diverse student population who are also beginning to work with datasets.  -->

Datasets provide the foundation for all of the large-scale machine learning systems we encounter today, and they are increasingly part of many other research fields and daily life. Many technical guides exist for learning to work with datasets, and much scholarship has emerged to study datasets critically [@corryCriticalDatasetStudies; @gillespieCriticalAlgorithmStudies2015]. Yet no guides attempt to combine technical and critical approaches comprehensively. Every dataset is partial, imperfect, and historically and socially contingent — yet the abundance of [problematic datasets and models] shows how little attention is given to these critical concerns in typical use. 

*A Critical Field Guide for Working with Machine Learning Datasets* helps navigate the complexity of working with giant datasets. Its accessible tone and zero assumed knowledge support direct use by practitioners of all stripes — activists, artists, journalists, scholars, students — anyone who is interacting with datasets in the wild and wants to use them in their work, while being mindful of their impacts. Developed with Kate Crawford and Mike Ananny, as part of their research team Knowing Machines, the field guide discusses parts and types of datasets, how they are transformed, why bias cannot be eliminated, and questions to ask at every stage of the dataset lifecycle. Importantly, it shares benefits of working critically with datasets when (on the surface) it may seem just as easy not to. 

The *Inclusive Datasets Research Guide* is an interactive digital guide for academic researchers working with datasets, that supports them with an overview of key concepts and considerations for working with datasets, as well as providing tools and software, books and tutorials, and recommendations for thinking inclusively. Like the Critical Field Guide, the Inclusive Datasets Research Guide focuses on a blend of technical and critical decisions that arise when working with datasets. Because this guide is aimed at students and teachers, the format is brief collections of resources rather than conceptual deep-dives. The guide appears on the USC Libraries' website along with its other research guides on many topics.

Developed by a team at USC Libraries, with the support of a grant from the USC Office of Research, this research guide was written as part of a grant to acquire core research datasets to support areas of inquiry by USC researchers into arts, humanities, and machine learning. I was recruited to provide interdisciplinary perspective on inclusive approaches to machine learning, and I joined a team including a chief library technologist, data science graduate students, special collections librarians, a research communications specialist, and a multimedia digital humanities specialist. We conducted 18 interviews with faculty across campus who worked with datasets in order to develop an internal rubric to support collection development. Through this process, we found that the need was less for dataset acquisition, because researchers did not look to libraries for their datasets but of course had access to many elsewhere. Still, the rubric we developed was utilized to acquire approximately 50 collections identified for being more accessible, inclusive, 'datafiable', and meaningfully engaged.  Instead, we found the need existed for more curated resources and more training on how to select and use datasets critically, while remaining mindful of their origins and impacts — which led to the expanded aim of the grant and the development of the *Inclusive Datasets Research Guide*

Both the Critical Field Guide and the Inclusive Datasets Research Guide reflect on the stakes of datasets and the human choices they relies on. Reframing the information in two different forms shows that it can be more effective in different contexts, depending on the audiences and the rhetorical tone they require. Both works are examples of how concepts and processes researched in the *Intersectional AI Toolkit* (below) can be reworked for new institutional contexts. Adapting the Toolkit to new audiences in library science, data science, and the social sciences posed interesting challenges that both expanded and refined the work. It required the ideas be scaled up and applied, and sometimes renegotiated until their rewordings no longer felt like watering down. So much of [the work] I am still learning, is about [people where they are][which means remembering that I have as much or more to learn from others than the other way around.] In each project, I got to learn how another field has addressed the problems of knowledge organization and bias, historically and in the present. Library scientists, of course, have at least a century of practice considering questions of how to categorize, curate, and archive. Social scientists have been asking how and what to measure for just as long. None of this is perfect, either, but learning from each institution, and combining thse with what machine learning is trying to ask, helps me understand better how we got where we are today. Combining these with what other intersectional practices may already understand helps me understand better what each domain might learn from the other. 

OBJECTIVES: Through the *Critical Field Guide for Working with Machine Learning Datasets* and the *Inclusive Datasets Research Guide*, understand the importance of working critically with datasets as part of any machine learning practice. Identify the parts, types, and functions of datasets as you encounter them. Determine whether a particular dataset is a good fit for your project by asking understanding critical questions to ask at each phase of the dataset lifecycle. [Work with the communities impacted by your research to create strategies for addressing potential harms in the datasets you utilize.] 

### SYSTEMS: *The Intersectional AI Toolkit*

<!-- Both of these texts apply concepts from the "Intersectional AI Toolkit," which argues that anyone should be able to understand what AI is and help shape what AI ought to be. The Toolkit's co-authored zines are accessible guides to both AI and intersectionality. They find common vocabularies to connect diverse communities around AI's urgent questions. Its online resources learn from legacies of queer, feminist, antiracist, anticolonialist, and antiablest theories, ethics, and tactics, showing how established but marginalized tactics are necessary for reimagining more critical and ethical machine learning. The Toolkit addresses anyone who wants to understand the automated systems that impact them by using public workshops, zines, and digital resources in order to describe key concepts and processes of machine learning through critical lenses.  -->

The *Intersectional AI Toolkit* argues that anyone should be able to understand AI and help shape its futures. Through collaborative sine-making workshops, it aims to find common vocabularies to connect diverse communities around AI's urgent questions. It clarifies, without math or jargon, the inner workings of AI systems and the ways in which they operate always as sociotechnical systems. The Toolkit celebrates intersectional work done by many other researchers and artists working to address these issues in interdisciplinary fields; and it gathers and synthesizes legacies of anti-racist, queer, transfeminist, neurodiverse, anti-ableist theories, ethics, and tactics that can contribute valuable perspective. Its three formats allow for multiple entry points: The digital wiki offers a forum for others to discuss and expand upon its topics. The collection of printed zines share AI topics at a concise, approachable scale. And the in-person and hybrid-online workshops invite multiple communities to participate directly in the systems that impact them.

Selecting the toolkit format was a key consideration of the development process for the *Intersectional AI Toolkit*. The toolkit form taken up here was first modeled after Ahmed's 'Killjoy Survival Kit' [@ahmedLivingFeministLife2017].[^killjoykit]. The term 'toolkit' was thoroughly contested — too instrumental and object-oriented — but settled upon after nothing else quite suited. Not compendium or catalogue or care package, not index or hub or gazetteer, not manifesto or knapsack or portal. The technologies used went through many iterations, from git repo to wiki to self-hosted hybrid back to repo again, in search of a platform that would facilitate guest user access without heavy onboarding, track edits, and adapt to multimedia zine forms. I am still remaking the work and searching for the perfect form. I suspect I will have to create it, and it will continue to change. In its various iterations, the Toolkit has grown into eleven zine-making workshops, compiled into eight printed zines, plus [xxx][eight][online topic pages]. Work on the Toolkit also resulted in the two related datasets projects, which reflected back to inform the Toolkit. Citizen data researcher Jennifer Gabrys says toolkits "provide instructions not just for assembly and use but also for attending to the social and political ramifications of digital devices." She says they are spaces of "instruction, contingency, action, and alternative engagement" [@gabrysHowThingsSensors2019]. As such, the *Intersectional AI Toolkit* hopes to provide resources and access points for engaging differently with machine learning systems in non-intimidating ways that connect different audiences.

[^killjoykit]: Ahmed says in *Living a Feminist Life* that the killjoy survival kit should contain books, things, tools, time, life, permission notes, other killjoys, humor, feelings, bodies, and your own survival kit.  

OBJECTIVES: Through the Intersectional AI Toolkit, the need for plural perspectives on AI systems. Understand key terminology related to machine learning and to intersectionality. Share perspectives on the impact of emerging technology as it relates to you. Choose critically which AI tools and resources you will engage and how.

<!--  Mattern: [@matternUnboxingToolkit2021] [Anthropologist Shannon Mattern details the many complex [lives] of 'kits', which can act as stop gaps for necessary infrastructure (bug out bags, refugee kits) or as "tools of engagement, as methods of inclusion, for broader communities" (rape kits)] --> 

### \*: *Interstitial Portals & Tactical Refusals*

<!-- As interstices among these three texts, a collection of five short lyric essays imagine dialogues with five 20th century artists, asking how the artists' analog material practices might act as pre-responses to the contemporary digital concerns raised across *Coding.Care*. "Codes for (Un)Raveling," "Codes for (Un)Limiting, "Codes for (Un)Forming," "Codes for (Un)Living," and "Codes for (Un)Knowing" approach the lived experience of an algorithmic era from oblique angles. Unlike the other texts, the tone of the "Codes" essays addresses nonpractitioners on a more affective, aesthetic register, meant for reflection on the impact of sociotechnical systems as they entangle with individuals and marginalized groups.  -->

* [(Un)Limiting](unlimiting.html): Rebecca Horn, constraint and COVID art
* [(Un)Raveling](unraveling.html): Sonya Rapoport, fiber art and computation
* [(Un)Forming](unforming.html): VALIE EXPORT, glitch feminism and broken machines
* [(Un)Living](unliving.html): On Kawara, dailiness, death, and data
* [(Un)Knowing](unknowing.html): Pipilotti Rist, black boxes and trauma

Michel de Montaigne called the essay form a 'trial' or 'attempt'. These interstitial essays are attempts to speak in the nearbyness of *Coding.Care*. They are trials, in the sense of struggles, to get closer to the core of the creature by sneaking between its ribs. An oblique strategy, they glance against logical modes of critical analysis or direct address, in order to become the [thing] and probe the [thing] and interrupt the [thing] [simultaneously]. 

As an alternate take on "bias" (because bias cannot be "optimized" out of systems), these are bias cuts moving diagonally or diffractively across the warp and weft of the fabric of the other texts here. Cutting and sewing on the bias puts fabric in tension, making garments that take the shape of the bodies they surround. Bias cuts are ways of working with and against materials, acknowledging their limits and not resolving them to right angles. Thus, these essays sustain the research tensions of *Coding.Care*, unfurling the questions in the materials rather than folding them away. 

Locating (and writing in) "a correspondence, not an assemblage," the essays join together by "living with" concepts [@ingoldLifeLines2015]. They are portals to a co-existing "past-present-future" [@olufemiExperimentsImaginingOtherwise2021] for exploring our relationships with systems differently and intimately, in which "the past is not lost, however, but rather a space of potential" [@chunDiscriminatingDataCorrelation2021]. [This is the threading together of nearbyness.]

>"the future is not in front of us, it is everywhere simultaneously: multidirectional, variant, spontaneous. We only have to *turn around*. Relational solidarities, even in their failure, reveal the plurality of the future-present, help us to see through the impasse, help temporarily eschew what is stagnant, help build and then prepare to shatter the many windows of the here and now." [@olufemiExperimentsImaginingOtherwise2021] 
<!-- >"The imagination is central to the cultural production of revolutionary movements; its primary role is to signal *what could be. What could be* is a lingistic stand-in for a set of political, social and cultural demands, strategic aims, revolutionary longings. As such, it resists singular definition."[@olufemiExperimentsImaginingOtherwise2021]   -->

As part of locating correspondences, the essays also use correspondance as a form, relying on epistolary address to conjure up analogue antecedents to the digital media discussed in other sections of *Coding.Care*. I read the works of several 20th century media artists as pre-responses to automated systems. Their wide range of practices — from minimalist daily rituals to queer feminist body art and performance — show how we have always—already been living in, talking about, performing with the questions amplified by automated systems, classification, and datification. Their works offer a breadth of artistic possibilities for reconsidering our relationships with computational systems — and these responses were already being established in parallel to the development of those systems. They help me reimagine how I want to respond now.

The essay form is a kind of embodied processing that moves the [corpus through the corpus], a reckoning in throat and gut that pairs bodily processing with computational processing. These interstitial essays serve, as queer scholar KJ Cerankowski writes, "to let this book be the crisis rather than about the crisis or crises, rather, a plurality of traumas and pains felt collectively and individually" [@cerankowskiSutureTraumaTrans2021]. Long traditions of artistic and literary outliers have maintained the need for such forms, like autotheory and lyric essay, which bridge aesthetic, personal, and political concerns. From these traditions, I am interested both in the constitutive act of form-making (as prefiguration) and in the reconsitituion of critical forms into poetic, personalized, or approachable forms [@fournierAutotheoryFeministPractice2021]. <!-- abolition -->

<!-- >"In projects like Theory Boner, artists and writers and curators come together to configure critical theory as something that must be processed and transmuted through the body and is very physical and even sexual in its effects on us; like [Hazel] Meyer's No Theory No Cry, [these works] make space for a way of relating to theory that is embodied, affective, and more directly relevant to the lives of queer and gender-nonconforming feminist artists, activists, and students. [@fournierAutotheoryFeministPractice2021] >"constituting life through the act of writing—rather than as expressive (describing a life that exists prior to the act of writing about it)." [@fournierAutotheoryFeministPractice2021]
-->

<!-- My favorite pieces of writing all feel permissive. In the moment of reading, I feel more alive with the realizataion, "it's allowed to write this way?" And then, the crash: "But who is allowed to write this way? Maybe only after certain requirements are met." I am never sure I am allowed, which is why I always want to try when I am lucky enough to feel supported to try, in hope that my doing so edges open a little more space for others and for othered writing forms. -->

<!-- [XXX][more?] -->

<!-- >Willis locates in the postcinematic "the imbrication of selves and systems, of agency alongside generative processes" "Our understanding of space [and time] shifts as it is coded computationally" "our viewing is becoming a process of navigating and our stories are the ones that we tell of our own experiences of traversal and exploration." "toward time as presence, performance and exchange. This is an era of acceleration, but also of duration, of elastic time flows and of layering;" "Practice becomes participatory and collaborative, manoeuvring through new conceptions of the spatial and temporal. [@willisFastForwardFuture2016] -->